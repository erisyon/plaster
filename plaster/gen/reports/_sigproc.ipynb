{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: REMOVE ME!\n",
    "from plaster.tools.ipynb_helpers.displays import restart_kernel; restart_kernel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Report v0.3`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"MPLCONFIGDIR\"] = \"/tmp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import itertools\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "from scipy.spatial.distance import cdist\n",
    "from IPython.display import HTML, display\n",
    "from plaster.run.calib.calib import RegPSF, approximate_psf\n",
    "from plaster.run.job import JobResult\n",
    "from plaster.run.plots import plots, plots_dev\n",
    "from plaster.run.plots.plots_sigproc import plot_psfs, circle_locs, sigproc_v2_im, sigproc_v2_movie_from_df, sigproc_v2_im_from_df\n",
    "from plaster.run.plots.plots_sigproc import wizard_xy_df, wizard_scat_df, wizard_raw_images\n",
    "from plaster.run.run import RunResult\n",
    "from plaster.run.sigproc_v2 import sigproc_v2_worker as worker\n",
    "from plaster.run.sigproc_v2.sigproc_v2_result import df_filter, radmat_from_df_filter, df_to_radmat, mean_non_dark_asr\n",
    "from plaster.run.sigproc_v2.synth import Synth\n",
    "from plaster.run.sigproc_v2 import bg\n",
    "from plaster.tools.image import imops\n",
    "from plaster.tools.image.coord import WH, XY, roi_shift, clip2d\n",
    "from plaster.tools.ipynb_helpers.displays import hd, movie, md, h\n",
    "from plaster.tools.log.log import error, debug\n",
    "from plaster.tools.schema import check\n",
    "from plaster.tools.utils import data\n",
    "from plaster.tools.utils import utils\n",
    "from plaster.tools.zap import zap\n",
    "from plaster.tools.zplots import zplots\n",
    "from plaster.tools.ipynb_helpers import displays\n",
    "from plaster.run.nn_v2.nn_v2_worker import triangle_dyemat\n",
    "z = zplots.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REMOVE ME\n",
    "# from plaster.run.base_result import enable_disk_memoize_from_notebook\n",
    "# enable_disk_memoize_from_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job = JobResult.from_context(dev_override=\"/erisyon/internal/jobs_folder/abbe7_1t\")\n",
    "run = job.sigproc_v2\n",
    "hd(\"h1\", f\"Analyzing {job.job_folder}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hd(\"h1\", f\"Frame Quality\")\n",
    "displays.explanation(\"\"\"\n",
    "    Summary:\n",
    "      * A per-frame (field, channel, cycle) measurement of quality.\n",
    "    \n",
    "    Definitions:\n",
    "      * \"Quality\" is a metric of low-frequency spectral characteristics.\n",
    "    \n",
    "    Notes:\n",
    "      * Uses a constant feature scale (not scaled by image dimension) and\n",
    "        therefore might vary drastically between the ifferent image sizes\n",
    "        that are recorded by different instruments.\n",
    "\"\"\")\n",
    "for ch_i in range(run.ims_import.n_channels):\n",
    "    hd(\"h2\", f\"Channel {ch_i}\")\n",
    "    qdf = run.ims_import.qualities()\n",
    "    qdf = qdf[(qdf.field_i < run.sigproc_v2.n_fields) & (qdf.channel_i == ch_i)].sort_values([\"quality\"])\n",
    "    z.hist(qdf.quality, _size_x=800, _size_y=150, f_title=f\"Quality distribution\")\n",
    "\n",
    "    row_iz = utils.ispace(0, len(qdf), 3)\n",
    "\n",
    "    # COMBINE all images for common percentile calculations\n",
    "    ims = np.concatenate([\n",
    "        run.sigproc_v2.aln_ims[row.field_i, row.channel_i, row.cycle_i].flatten()\n",
    "        for row in qdf.iloc[row_iz].itertuples()\n",
    "    ])\n",
    "    bot, top = np.percentile(ims, (50, 99.9))\n",
    "\n",
    "    # SHOW example of worst, median, and best all using the same cspan\n",
    "    hd(\"h3\", f\"Examples of frames by quality\")\n",
    "    with z(_cols=3, _cspan=(bot, top)):\n",
    "        names = (\"worst\", \"median\", \"best\")\n",
    "        for name, row in zip(names, qdf.iloc[row_iz].itertuples()):\n",
    "            z.im(run.sigproc_v2.aln_ims[row.field_i, row.channel_i, row.cycle_i], f_title=f\"{name} fl_i={row.field_i} cy_i={row.cycle_i}, qual={row.quality:.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hd(\"h1\", f\"Field Quality\")\n",
    "displays.explanation(\"\"\"\n",
    "    Summary:\n",
    "      * Per-field summaries of the \"Quality\" metric. (See above\n",
    "        definitions and warnings.)\n",
    "    \n",
    "    Notes:\n",
    "      * Each bar is the mean quality of all cycles for each field.\n",
    "      * Channels are independent plots.\n",
    "      \n",
    "    Todo:\n",
    "      * Add error bars\n",
    "\"\"\")\n",
    "for ch_i in range(run.ims_import.n_channels):\n",
    "    hd(\"h2\", f\"Channel {ch_i}\")\n",
    "    qdf = run.ims_import.qualities()\n",
    "    qdf = qdf[(qdf.field_i < run.sigproc_v2.n_fields) & (qdf.channel_i == ch_i)].sort_values([\"quality\"])\n",
    "    mean_qual = qdf.groupby(\"field_i\").mean().reset_index().sort_values(\"field_i\")\n",
    "    z.cols(\n",
    "        mean_qual.quality,\n",
    "        _size_x=800, _size_y=150,\n",
    "        f_title=f\"Mean quality distribution\",\n",
    "        f_x_axis_label=\"Field\",\n",
    "        f_y_axis_label=\"Mean quality\",\n",
    "        f_toolbar_location=\"above\",\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hd(\"h1\", f\"Field Alignment\")\n",
    "displays.explanation(\"\"\"\n",
    "    Summary:\n",
    "      * Maximum shift in pixels required to align cycles for each field.\n",
    "    \n",
    "    Notes:\n",
    "      * When a cycle fails to align it is typically dramatic and the shift will be\n",
    "        very different from other fields.\n",
    "      * The failures are typically caused by anomalies (contamination, etc) that\n",
    "        confuses the aligner. Eventually the anomaly mask algorithm will be resurrected\n",
    "        and will prevent many such failures to align.\n",
    "\"\"\")\n",
    "field_df = run.sigproc_v2.fields().copy()\n",
    "field_df[\"alignment\"] = np.sqrt(field_df.aln_x**2 + field_df.aln_y**2)\n",
    "alignment = field_df.groupby(\"field_i\").alignment.max().values\n",
    "z.cols(alignment, f_x_axis_label=\"field_i\", f_y_axis_label=\"Max shift in pixels\", f_title=\"Max alignment distance by field\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def features(run, ch_i=0, dyts=None):\n",
    "    \"\"\"\n",
    "    Extract standard features for every peak\n",
    "    \"\"\"\n",
    "    df = run.sigproc_v2.peaks()\n",
    "\n",
    "    # Merge in stage metadata\n",
    "    stage_df = (\n",
    "        run.ims_import.metadata()[[\"field_i\", \"stage_x\", \"stage_y\"]]\n",
    "        .groupby(\"field_i\")\n",
    "        .mean()\n",
    "    )\n",
    "    df = pd.merge(left=df, right=stage_df, left_on=\"field_i\", right_on=\"field_i\")\n",
    "    df[\"flowcell_x\"] = df.stage_x + df.aln_x\n",
    "    df[\"flowcell_y\"] = df.stage_y + df.aln_y\n",
    "\n",
    "    sig = run.sigproc_v2.sig()[:, ch_i, :]\n",
    "    assert sig.shape[0] == len(df)\n",
    "\n",
    "    asr = run.sigproc_v2.aspect_ratio()[:, ch_i, :]\n",
    "    assert asr.shape[0] == len(df)\n",
    "\n",
    "    has_neighbor_stats = run.sigproc_v2.has_neighbor_stats()\n",
    "    if has_neighbor_stats:\n",
    "        nei = run.sigproc_v2.neighborhood_stats()\n",
    "        assert nei.shape[0] == len(df)\n",
    "\n",
    "    # Convenience aliases\n",
    "    n_cycles = run.sigproc_v2.n_cycles\n",
    "    n_peaks = df.peak_i.max() + 1\n",
    "    im_mea = run.ims_import.dim\n",
    "\n",
    "    # \"Lifespan\" is the cycles over which a peak is \"on\". Abbrevaited \"lif\"\n",
    "    # Use the cosine distance to determine lif_len\n",
    "    dyts1, _ = triangle_dyemat(n_cycles, n_dyes=1, include_nul_row=False)\n",
    "    dyt1_dists = cdist(sig, dyts1, 'cosine')\n",
    "    lif_len = np.argmin(dyt1_dists, axis=1) + 1  # Add one because we removed the nul row\n",
    "\n",
    "    row_iz, col_iz = np.indices(sig.shape)\n",
    "    sig_lif = np.where(col_iz < lif_len[:, None], sig, np.nan)\n",
    "    asr_lif = np.where(col_iz < lif_len[:, None], asr, np.nan)\n",
    "\n",
    "    # \"afl\" stands for \"afterlife\"\n",
    "    sig_afl = np.where(col_iz >= lif_len[:, None], sig, np.nan)\n",
    "\n",
    "    if has_neighbor_stats:\n",
    "        nei_men_lif = np.where(col_iz < lif_len[:, None], nei[:, :, 0], np.nan)\n",
    "        nei_std_lif = np.where(col_iz < lif_len[:, None], nei[:, :, 1], np.nan)\n",
    "        nei_med_lif = np.where(col_iz < lif_len[:, None], nei[:, :, 2], np.nan)\n",
    "        nei_iqr_lif = np.where(col_iz < lif_len[:, None], nei[:, :, 3], np.nan)\n",
    "    else:\n",
    "        nei_men_lif = np.zeros((n_peaks, n_cycles))\n",
    "        nei_std_lif = np.zeros((n_peaks, n_cycles))\n",
    "        nei_med_lif = np.zeros((n_peaks, n_cycles))\n",
    "        nei_iqr_lif = np.zeros((n_peaks, n_cycles))\n",
    "\n",
    "    df[\"radius\"] = np.sqrt(\n",
    "        (df.aln_x - im_mea // 2) ** 2 + (df.aln_y - im_mea // 2) ** 2\n",
    "    )\n",
    "\n",
    "    with utils.np_no_warn():\n",
    "        df[\"lif_len\"] = lif_len\n",
    "        df[\"lif_med\"] = np.nanmedian(sig_lif, axis=1)\n",
    "        df[\"lif_men\"] = np.nanmean(sig_lif, axis=1)\n",
    "        df[\"lif_std\"] = np.nanstd(sig_lif, axis=1)\n",
    "        df[\"lif_iqr\"] = np.subtract(*np.nanpercentile(sig_lif, [75, 25], axis=1))\n",
    "        df[\"lif_max\"] = np.nanmax(sig_lif, axis=1)\n",
    "        df[\"lif_min\"] = np.nanmin(sig_lif, axis=1)\n",
    "        df[\"lif_rng\"] = df.lif_max - df.lif_min\n",
    "\n",
    "        df[\"afl_med\"] = np.nanmedian(sig_afl, axis=1)\n",
    "        df[\"afl_men\"] = np.nanmean(sig_afl, axis=1)\n",
    "        df[\"afl_std\"] = np.nanstd(sig_afl, axis=1)\n",
    "        df[\"afl_iqr\"] = np.subtract(*np.nanpercentile(sig_afl, [75, 25], axis=1))\n",
    "        df[\"afl_max\"] = np.nanmax(sig_afl, axis=1)\n",
    "        df[\"afl_min\"] = np.nanmin(sig_afl, axis=1)\n",
    "        df[\"afl_rng\"] = df.afl_max - df.afl_min\n",
    "\n",
    "        df[\"nei_men\"] = np.nanmean(nei_men_lif, axis=1)\n",
    "        df[\"nei_std\"] = np.nanmean(nei_std_lif, axis=1)\n",
    "        df[\"nei_med\"] = np.nanmean(nei_med_lif, axis=1)\n",
    "        df[\"nei_iqr\"] = np.nanmean(nei_iqr_lif, axis=1)\n",
    "\n",
    "        df[\"sig_med\"] = np.median(sig, axis=1)\n",
    "        df[\"sig_men\"] = np.mean(sig, axis=1)\n",
    "        df[\"sig_std\"] = np.std(sig, axis=1)\n",
    "        df[\"sig_iqr\"] = np.subtract(*np.nanpercentile(sig, [75, 25], axis=1))\n",
    "        df[\"sig_max\"] = np.max(sig, axis=1)\n",
    "        df[\"sig_min\"] = np.min(sig, axis=1)\n",
    "        df[\"sig_rng\"] = df.sig_max - df.sig_min\n",
    "\n",
    "        df[\"asr_med\"] = np.nanmedian(asr_lif, axis=1)\n",
    "        df[\"asr_std\"] = np.nanstd(asr_lif, axis=1)\n",
    "        df[\"asr_max\"] = np.nanmax(asr_lif, axis=1)\n",
    "        df[\"asr_cy0\"] = asr[:, 0]\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unfilt_fea_df = features(run)\n",
    "n_peaks = unfilt_fea_df.peak_i.max() + 1\n",
    "n_cycles = run.sigproc_v2.n_cycles\n",
    "sig = run.sigproc_v2.sig()\n",
    "\n",
    "hd(\"h1\", f\"Aspect ratios @ cycle=0, all channels\")\n",
    "displays.explanation(\"\"\"\n",
    "    Summary:\n",
    "      * Left-side:\n",
    "          Distribution of peak aspect-ratios on first cycle (a proxy for collisions).\n",
    "          The red-line is a threshold used in later filters.\n",
    "      * Right-side:\n",
    "          Distribution of maximum ASR for each peak over its lifespan (on cycles).\n",
    "    \n",
    "    Definition:\n",
    "      * \"Aspect Ratio\" (abbrevatied as \"ASR\") is the ratio of the longest to the\n",
    "        shortest axis of a peak's pixels.\n",
    "    \n",
    "    Notes:\n",
    "      * Currently filters only use ASR at cycle 0. A proposal has been made\n",
    "        to convert this to the mean of all cycles so that we might detect\n",
    "        situations where a collision comes in and out of a cycle.\n",
    "      * The ASR Threshold was determined by simulating two peaks moving\n",
    "        towards each other and findind the point at which the aspect ratio\n",
    "        is a good predictor of a collision. This point was determined\n",
    "        informally but probably wouldn't change much under a stricter definition.\n",
    "\"\"\")\n",
    "asr_thresh = run.sigproc_v2.asr_threshold()\n",
    "\n",
    "asr = unfilt_fea_df.asr_cy0\n",
    "asr_mask = asr < asr_thresh\n",
    "n_keep = asr_mask.sum()\n",
    "fea_df = unfilt_fea_df[asr_mask]\n",
    "# fea_df from here forward is aspect_ratio filtered\n",
    "\n",
    "hd(\"h2\", f\"Keep {100 * n_keep / n_peaks:.1f}%, Reject {100 * (n_peaks-n_keep) / n_peaks:.1f}%\")\n",
    "_bins = (1, 3, 200)\n",
    "with z(_cols=2, _range=z.hist_range(asr, _bins=_bins), _bins=_bins, f_x_axis_label=\"ASR\", f_y_axis_label=\"# peaks\"):\n",
    "    z.hist(asr, _vertical=asr_thresh, f_title=\"Distr. Aspect-ratio at cycle=0\")\n",
    "    z.hist(unfilt_fea_df.asr_max, f_title=\"Dist. Aspect-ratio max over lifespan cycles\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hd(\"h1\", f\"Cycle Balance\")\n",
    "displays.explanation(\"\"\"\n",
    "    Summary:\n",
    "      * Shows the relative correction that is applied to each cycle.\n",
    "    \n",
    "    Definitions:\n",
    "      * \"Relative Brightness\": Each cycle's median peak intensity is computed\n",
    "        using any peak that is \"alive\" during that cycle.\n",
    "        1.0 = mean cycle brightness.\n",
    "    \n",
    "    Notes:\n",
    "      * The mean of cycle brightnesses is found and used to normalized the y axis.\n",
    "        So 1.0 is the \"mean cycle intensity\". \"1.4\" would mean that a given cycle\n",
    "        was 40% brighter than the mean cycle.\n",
    "\"\"\")\n",
    "\n",
    "sig_ch0 = sig[fea_df.peak_i, 0, :]\n",
    "sig_ch0_lif = np.where(np.arange(n_cycles)[None, :] < fea_df.lif_len[:, None], sig_ch0, np.nan)\n",
    "cy_bal = np.nanmean(sig_ch0_lif, axis=0)\n",
    "cy_bal /= np.median(cy_bal)\n",
    "bal_sig = sig / cy_bal\n",
    "\n",
    "cum_n_dark = np.zeros((n_cycles,))\n",
    "for cy_i in range(n_cycles):\n",
    "    cum_n_dark[cy_i] = (fea_df.lif_len <= cy_i).sum()\n",
    "\n",
    "# TODO: Multi-channel\n",
    "with z(_cols=2):\n",
    "    z.cols(\n",
    "        cy_bal,\n",
    "        f_title=\"Cycle balance\",\n",
    "        f_x_axis_label=\"Cycle\",\n",
    "        f_y_axis_label=\"Relative brightness (1.0 = mean)\",\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hd(\"h1\", f\"Filters and Features\")\n",
    "displays.explanation(\"\"\"\n",
    "    Summary:\n",
    "      * Shows distrbution of peaks by various features some of which are used\n",
    "        for filtering.\n",
    "    \n",
    "    Definitions:\n",
    "      * \"Aspect Ratio\": (abbrevatied as \"ASR\") is the ratio of the longest to the\n",
    "        shortest axis of a peak's pixels.\n",
    "      * \"Dropped after cycle X\": Determined by the lifespan metric\n",
    "        (ie, a binary step fitter)\n",
    "      * \"Remainders\": Peaks that were still bright on the last cycle\n",
    "    \n",
    "    Notes:\n",
    "      * Currently ASR is the only filter and is applied to most subsequent plots.\n",
    "\"\"\")\n",
    "\n",
    "n_asr_pass, n_asr_reject = asr_mask.sum(), n_peaks - asr_mask.sum()\n",
    "\n",
    "bars = [\n",
    "    [n_asr_pass, n_asr_reject],\n",
    "    [(fea_df.lif_len == cy_i).sum() for cy_i in range(1, n_cycles+1)],\n",
    "]\n",
    "labels = [\n",
    "    [f\"asr_pass\", f\"asr_reject\"],\n",
    "    [(f\"dropped after cycle {cy_i}\" if cy_i < (n_cycles-1) else \"remainders\") for cy_i in range(0, n_cycles)],\n",
    "]\n",
    "z.count_stack(bars, labels, _size=(1000, 100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hd(\"h1\", f\"Lifespans\")\n",
    "displays.explanation(\"\"\"\n",
    "    Summary:\n",
    "      * Shows distrbution of peak lifespans\n",
    "    \n",
    "    Definitions:\n",
    "      * \"Lifespan\": The number of cycles a peak is \"on\".\n",
    "      * \"Afterlife\" (abbrev. \"afl\"): The values of cycles after the peak is\n",
    "        declated off.\n",
    "    \n",
    "    Notes:\n",
    "      * Lifespan is determined by a binary step function fitter using \n",
    "        cosine distance. It is not particularly sensitive to the\n",
    "        brightness of the spot (ie, count, etc.)\n",
    "\"\"\")\n",
    "\n",
    "with z(_cols=3):\n",
    "    with z(_range=z.hist_range(fea_df.lif_med)):\n",
    "        with z(f_x_axis_label=\"median intensity (rad. units) of lifespan\", f_y_axis_label=\"# peaks\"):\n",
    "            z.hist(\n",
    "                fea_df.lif_med,\n",
    "                f_title=\"Distr. of lifespan medians (ch 0)\",\n",
    "            )\n",
    "\n",
    "            z.hist(\n",
    "                fea_df[fea_df.lif_len < n_cycles].lif_med,\n",
    "                f_title=\"Distr. of lifespan meds. (ch 0) excluding remainders\",\n",
    "            )\n",
    "\n",
    "            z.hist(\n",
    "                fea_df.afl_med,\n",
    "                f_title=\"Distr. of after-life meds.\",\n",
    "            )\n",
    "\n",
    "    z.hist(\n",
    "        fea_df.lif_len,\n",
    "        _bins=(0, run.sigproc_v2.n_cycles, run.sigproc_v2.n_cycles),\n",
    "        f_title=\"Distr. of lifespan lengths (ch 0)\",\n",
    "        f_x_axis_label=\"lifespan in cycles\",\n",
    "        f_y_axis_label=\"# peaks\",\n",
    "    )\n",
    "\n",
    "    cum_n_dark = np.zeros((n_cycles,))\n",
    "    for cy_i in range(n_cycles):\n",
    "        cum_n_dark[cy_i] = (fea_df.lif_len <= cy_i).sum()\n",
    "    z.cols(\n",
    "        100 * cum_n_dark / n_peaks,\n",
    "        f_title=\"Cummulate # peaks dropped to dark (ch 0)\",\n",
    "        f_x_axis_label=\"cycle\",\n",
    "        f_y_axis_label=\"% peaks dark by cycle\",\n",
    "        _range_y=(0, 100)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hd(\"h1\", f\"Monotonicity\")\n",
    "displays.explanation(\"\"\"\n",
    "    Summary:\n",
    "      * Left-side:\n",
    "          - Distribution of \"monotonic metric\".\n",
    "          - Red line is the \"monotonic threshold\"\n",
    "      * Right-side:\n",
    "          - Sampling of peaks where \"monotonic metric\" exceeds\n",
    "            the \"monotonic threshold\"\n",
    "            \n",
    "    Definitions:\n",
    "      * \"Monotonic metric\" is the maximum increase in radiometry intensity over\n",
    "        the lifespan divided by the mean radiometric intensity of the lifespan.\n",
    "      * \"Monotonic threshold\" is chosen arbitrarily to be 1.0.\n",
    "    \n",
    "    Filters applied:\n",
    "      * aspect ratio\n",
    "      * cycle balance\n",
    "    \n",
    "    Notes:\n",
    "      * The metric is noisy for lifespans under 5 cycles and therefore\n",
    "        is only shown for peaks with lifespans >= 5 cycles.\n",
    "      * The units are set by the mean of each row so 1.0 means that there\n",
    "        was some rise equal a full value of the row. For counts > 1, this\n",
    "        will under-estimate the monotonicity as higher counts will lead to\n",
    "        higher intensityies and thus an unfarly larger increase for a row\n",
    "        to be declared \"non-monotonic\".\n",
    "\"\"\")\n",
    "\n",
    "sig0 = bal_sig[fea_df.peak_i, 0, :]\n",
    "bot, top = np.percentile(sig0, (50, 99))\n",
    "_, col_iz = np.indices(sig0.shape)\n",
    "sig0_lif = np.where(col_iz < fea_df.lif_len[:, None], sig0, np.nan)\n",
    "monotonic_threshold = 1.0\n",
    "with utils.np_no_warn():\n",
    "    d = np.diff(sig0_lif, axis=1)\n",
    "    maxs_diff = np.nanmax(d, axis=1)\n",
    "    mens = np.nanmean(sig0_lif, axis=1)\n",
    "    monotonic_metric = maxs_diff / mens\n",
    "    lif_gt_4_mask = fea_df.lif_len > 4\n",
    "    n_peaks_lif_gt_4 = lif_gt_4_mask.sum()\n",
    "    monotonic_metric_lif_gt_4 = maxs_diff[lif_gt_4_mask] / mens[lif_gt_4_mask]\n",
    "    n_non_monotonic_lif_gt_4 = (monotonic_metric_lif_gt_4 > monotonic_threshold).sum()\n",
    "    hd(\"h2\", f\"% Non-monotonic (of peaks with > 4 lifespan): {100 * n_non_monotonic_lif_gt_4 / n_peaks_lif_gt_4:.1f}%\")\n",
    "    mask = (maxs_diff / mens > monotonic_threshold) & lif_gt_4_mask\n",
    "\n",
    "    with z(_cols=2):\n",
    "        z.hist(\n",
    "            monotonic_metric_lif_gt_4,\n",
    "            _bins=(0, 3, 200),\n",
    "            f_title=\"Distr. of monotonic metric (peaks w/ life > 4)\",\n",
    "            f_x_axis_label=\"max. rad. inten. gain in lifespan / lif_mean\",\n",
    "            f_y_axis_label=\"# peaks\",\n",
    "            _vertical=monotonic_threshold\n",
    "        )\n",
    "        \n",
    "        mdf = fea_df.sort_values([\"peak_i\"])[mask]\n",
    "        _hover_rows=dict(peak_i=mdf.peak_i, field_i=mdf.field_i)\n",
    "        z.im_clus(\n",
    "            sig0[mask],\n",
    "            _n_samples=500,\n",
    "            _cspan=(bot, top),\n",
    "            f_title=\"Sample of sigfinicantly non-monotonic rows\",\n",
    "            f_x_axis_label=\"# peaks\",\n",
    "            _hover_rows=_hover_rows,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hd(\"h1\", f\"Heatmaps\")\n",
    "displays.explanation(\"\"\"\n",
    "    Summary:\n",
    "      * Heatmaps of random subsample of peaks. Rows are peaks, Columns are Cycles\n",
    "            \n",
    "    Definitions:\n",
    "      * \"Clustered by row\": heirarchical clustering that puts similar\n",
    "        row patterns together\n",
    "      * \"Sorted by mean life. intensity\": Sorted using the mean of the\n",
    "        intensity during a peak's lifespan.\n",
    "      * \"Signal sorted by (lif_len, lif_mean)\": Sort first by the\n",
    "        assigned lifespan and then within that sort by the mean intensity\n",
    "        during the lifespan.\n",
    "      * \"Signal sorted by (field_i, lif_len, lif_mean)\": Same but with field\n",
    "        as the first sort axis.\n",
    "    \n",
    "    Filters applied:\n",
    "      * aspect ratio\n",
    "      * cycle balance\n",
    "      \n",
    "    Notes:\n",
    "      * This images may change on each execution as they involve random sampling.\n",
    "\"\"\")\n",
    "\n",
    "for ch_i in range(run.ims_import.n_channels):\n",
    "    hd(\"h2\", f\"Channel {ch_i}\")\n",
    "\n",
    "    bot, top = np.percentile(bal_sig, (50, 99))\n",
    "    with z(_cols=2, _size=500, _cspan=(bot, top)):\n",
    "        mdf = fea_df.sort_values([\"peak_i\"])\n",
    "        _hover_rows=dict(peak_i=mdf.peak_i, field_i=mdf.field_i)\n",
    "        axis_labels = dict(f_x_axis_label=\"cycle\", f_y_axis_label=\"peaks\")\n",
    "        z.im_clus(\n",
    "            bal_sig[mdf.peak_i, ch_i, :],\n",
    "            _hover_rows=_hover_rows,\n",
    "            _n_samples=500,\n",
    "            f_title=\"Signal clustered by row\",\n",
    "            **axis_labels\n",
    "        )\n",
    "\n",
    "        mdf = fea_df.sort_values([\"sig_men\"])\n",
    "        z.im(\n",
    "            bal_sig[mdf.peak_i, ch_i, :],\n",
    "            _hover_rows=_hover_rows,\n",
    "            f_title=\"Signal sorted by mean life. intensity\",\n",
    "            **axis_labels\n",
    "        )\n",
    "\n",
    "        mdf = fea_df.sample(1000).sort_values([\"lif_len\", \"lif_men\"])\n",
    "        z.im(\n",
    "            bal_sig[mdf.peak_i, ch_i, :],\n",
    "            _hover_rows=dict(peak_i=mdf.peak_i, field_i=mdf.field_i),\n",
    "            f_title=\"Signal sorted by (lif_len, lif_mean)\",\n",
    "            **axis_labels\n",
    "        )\n",
    "\n",
    "        mdf = fea_df.sample(1000).sort_values([\"field_i\", \"lif_len\", \"lif_men\"])\n",
    "        z.im(\n",
    "            bal_sig[mdf.peak_i, ch_i, :],\n",
    "            _hover_rows=dict(peak_i=mdf.peak_i, field_i=mdf.field_i),\n",
    "            f_title=\"Signal sorted by (field_i, lif_len, lif_mean)\",\n",
    "            **axis_labels\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hd(\"h1\", f\"Signal to Noise Ratios\")\n",
    "displays.explanation(\"\"\"\n",
    "    Summary:\n",
    "      * Distribution of \"Signal to Noise Ratio\".\n",
    "            \n",
    "    Definitions:\n",
    "      * \"Signal to Noise Ratio\" is the radiometry signal divided\n",
    "        by the \"Noise Estimate\"\n",
    "      * \"Noise Estimate\" is standard deviation of the residuals\n",
    "        of the fit signal peak to the actual peak.\n",
    "    \n",
    "    Filters applied:\n",
    "      * aspect ratio\n",
    "    \n",
    "    Notes:\n",
    "      * There will always be a strong peak with mean at zero. These\n",
    "      are the dark cycles.\n",
    "\"\"\")\n",
    "\n",
    "for ch_i in range(run.ims_import.n_channels):\n",
    "    hd(\"h2\", f\"Channel {ch_i}\")\n",
    "    _snr = run.sigproc_v2.snr()[fea_df.peak_i, ch_i, :]\n",
    "    z.hist(_snr, f_title=f\"Distr. of SNR channel={ch_i}\", f_x_axis_label=\"SNR\", f_y_axis_label=\"n_peaks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hd(\"h1\", f\"Peak Feature Relationships\")\n",
    "displays.explanation(\"\"\"\n",
    "    Summary:\n",
    "      * All-feature to all-feature scatters. Each blue dot is a randomly\n",
    "        sampled peak.\n",
    "            \n",
    "    Definitions:\n",
    "      * field_i: Field index\n",
    "      * aln_x, _y: Aligned coordinate in pixels relative to field\n",
    "      * flowcell_x, _y: Field stage coordinate (in microns?)\n",
    "        plus aln_x, aln_y (in pixels). Note that this is adding apples\n",
    "        and oranges (need a portable conversion factor)!\n",
    "      * radius: Distance in pixels from center of field.\n",
    "      * lif_len: Lifespan of peak in cycles\n",
    "      * lif_med: Median rad. intensity during lifespan\n",
    "      * lif_iqr: IQR of rad. intensity during lifespan\n",
    "      * afl_med: Median rad. intensity after the the lifespan (afterlife)\n",
    "      * afl_iqr: IQR of rad. intensity after the the lifespan (afterlife)\n",
    "      * nei_med: Median of neighborhood pixels (sometimes disabled)\n",
    "      * nei_iqr: IQR of neighborhood pixels (sometimes disabled)\n",
    "      * sig_med: Median of rad. intensity over all cycles (compare the lif_med)\n",
    "      * sig_iqr: IQR of rad. intensity over all cycles\n",
    "      * asr_cy0: Aspect ratio (ASR) at cycle 0\n",
    "      * asr_max: Max. aspect ratio through lifespan\n",
    "    \n",
    "    Filters applied:\n",
    "      * aspect ratio\n",
    "      * lifespan < n_cycles (ie, no remainders)\n",
    "    \n",
    "    Notes:\n",
    "      * 1000 peaks are drawn randomly. All plots use the same 1000 peaks.\n",
    "      * A conversion factor from pixels to microns is needed for \n",
    "        a correct value of flowcell_x, _y.\n",
    "      * The neighborhood measurement is not always availble.\n",
    "\"\"\")\n",
    "\n",
    "mask = fea_df.lif_len < n_cycles\n",
    "mdf = fea_df[mask]\n",
    "cols = [\n",
    "    \"field_i\", \"aln_y\", \"aln_x\", \"flowcell_y\", \"flowcell_x\", \"radius\",\n",
    "    \"lif_len\", \"lif_med\", \"lif_iqr\",\n",
    "    \"afl_med\", \"afl_iqr\",\n",
    "    \"nei_med\", \"nei_iqr\",\n",
    "    \"sig_med\", \"sig_iqr\",\n",
    "    \"asr_cy0\", \"asr_max\"\n",
    "]\n",
    "mdf = mdf.sample(1000)\n",
    "with z(_cols=len(cols), _notools=True, _noaxes=True, _size=70, alpha=0.1):\n",
    "    for yi, col_y in enumerate(cols):\n",
    "        for xi, col_x in enumerate(cols):\n",
    "            f_title = col_x if yi == 0 else \"\"\n",
    "            f_y_axis_label = col_y if xi == 0 else \"\"\n",
    "            z.scat(x=mdf[col_x], y=mdf[col_y], f_title=f_title, f_y_axis_label=f_y_axis_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hd(\"h1\", f\"Calibration\")\n",
    "displays.explanation(\"\"\"\n",
    "    Summary:\n",
    "      * PSF and Regional Illumination Stats from calibration\n",
    "            \n",
    "    Definitions:\n",
    "      * \"PSF\": The regional Point-Spread-Function.\n",
    "      * \"Regional Illumination Balance\": The foreground illumination balance found regionally\n",
    "      * \"Calibration\": When an independent 1-count experiment is used to measeure PSF and Illum. balance.\n",
    "      * \"Self-Calibration\": When the run itself is used to estimate these parameters.\n",
    "    \n",
    "    Filters applied:\n",
    "      * None\n",
    "\"\"\")\n",
    "\n",
    "print(f\"Uses self-calibration: {run.sigproc_v2.params.self_calib}\")\n",
    "print(f\"Uses calibration_file: {run.sigproc_v2.params.calibration_file}\")\n",
    "print(f\"Uses instrument_identity: {run.sigproc_v2.params.instrument_identity}\")\n",
    "\n",
    "for ch_i in range(run.ims_import.n_channels):\n",
    "    hd(\"h2\", f\"Channel {ch_i}\")\n",
    "\n",
    "    with z(_cols=3, _size=250):\n",
    "        reg_psf = run.sigproc_v2.calib.reg_psf(ch_i=ch_i)\n",
    "        check.t(reg_psf, RegPSF)\n",
    "        psf_ims = reg_psf.render()\n",
    "        plot_psfs(psf_ims, scale=3.0, f_title=f\"Regional PSF\", _noaxes=True, _notools=True, _zplots_context=z)\n",
    "\n",
    "        z.cols(\n",
    "            np.max(reg_psf.params[ch_i][:, :, 0:2], axis=2).flatten(),\n",
    "            f_x_axis_label=\"Region #\",\n",
    "            f_y_axis_label=\"peak size\",\n",
    "            f_title=\"Regional PSF peak size\",\n",
    "        )\n",
    "\n",
    "        illum = run.sigproc_v2.calib.reg_illum().interp(ch_i)\n",
    "        z.im(1.0 / illum, f_title=\"Regional Illumination Balance Map\", _cspan=(0, 1.0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hd(\"h1\", f\"Signal distributions\")\n",
    "displays.explanation(\"\"\"\n",
    "    Summary:\n",
    "      * Signal distributions.\n",
    "            \n",
    "    Filters applied:\n",
    "      * Aspect Ratio\n",
    "      \n",
    "    Notes:\n",
    "      * The distr. plots show:\n",
    "          - gray line for the (0-99) percentiles\n",
    "          - black line for the (20-75) percentiles (\"IQR\")\n",
    "          - white tick for the median\n",
    "      * The red vertical line is the same in all plots and is simply\n",
    "        a visual reference set to a guess of the beta parameter.\n",
    "\"\"\")\n",
    "\n",
    "n_peaks_per_field = run.sigproc_v2.peaks().groupby(\"field_i\").count().field_peak_i\n",
    "n_peaks_max = np.max(n_peaks_per_field)\n",
    "n_fields = run.sigproc_v2.n_fields\n",
    "for ch_i in range(run.ims_import.n_channels):\n",
    "    hd(\"h2\", f\"Channel {ch_i}\")\n",
    "\n",
    "    sig_ch = bal_sig[fea_df.peak_i, ch_i, :]\n",
    "    sig_ch_lif = np.where(np.arange(n_cycles)[None, :] < fea_df.lif_len[:, None], sig_ch, np.nan)\n",
    "\n",
    "    dark = run.sigproc_v2.dark_estimate(ch_i=ch_i)\n",
    "    sig_ch = bal_sig[fea_df.peak_i, ch_i, :]\n",
    "    beta_est = np.median(sig_ch[sig_ch > dark])\n",
    "\n",
    "    bot, top = np.nanpercentile(sig_ch, (0.1, 99.0))\n",
    "    with z(_cols=3, _bins=(bot, top, 200), _range_x=(bot, top)):\n",
    "        z.hist(\n",
    "            sig_ch,\n",
    "            _vertical=beta_est,\n",
    "            f_x_axis_label=\"Signal (Rad. units)\",\n",
    "            f_title=\"Signal distributions, all cycles, all fields\"\n",
    "        )\n",
    "        \n",
    "        with z(_range=z.hist_range(sig_ch[:, -1])):\n",
    "            z.hist(\n",
    "                sig_ch[:, 0],\n",
    "                _vertical=beta_est,\n",
    "                f_x_axis_label=\"Signal (Rad. units)\",\n",
    "                f_title=\"Signal distributions, cycle=0, all fields\"\n",
    "            )\n",
    "\n",
    "            z.hist(\n",
    "                sig_ch[:, -1],\n",
    "                _vertical=beta_est,\n",
    "                f_x_axis_label=\"Signal (Rad. units)\",\n",
    "                f_title=\"Signal distributions, cycle=last, all fields\"\n",
    "            )\n",
    "\n",
    "    sig_ch_cy0_by_field = np.full((n_fields, n_peaks_max), np.nan)\n",
    "    for fl_i in range(n_fields):\n",
    "        fl_mask = fea_df.field_i == fl_i\n",
    "        _sig_ch_cy0 = sig_ch[fl_mask, 0]\n",
    "        sig_ch_cy0_by_field[fl_i, 0:len(_sig_ch_cy0)] = _sig_ch_cy0\n",
    "\n",
    "    with z(_cols=2):\n",
    "        z.distr(\n",
    "            sig_ch_lif.transpose(1,0),\n",
    "            _vertical=beta_est,\n",
    "            _percentiles=(0, 25, 50, 75, 99),\n",
    "            _nogrid=True,\n",
    "            f_x_axis_label=\"Signal\",\n",
    "            f_y_axis_label=\"Cycle\",\n",
    "            f_title=\"Distr. of life signal by cycle, all fields\"\n",
    "        )\n",
    "\n",
    "        z.distr(\n",
    "            sig_ch_cy0_by_field,\n",
    "            _vertical=beta_est,\n",
    "            _percentiles=(0, 25, 50, 75, 99),\n",
    "            _nogrid=True,\n",
    "            f_x_axis_label=\"Signal\",\n",
    "            f_y_axis_label=\"Field\",\n",
    "            f_title=\"Distr. of signal @ cycle=0, by field\"\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hd(\"h1\", f\"Peak density\")\n",
    "displays.explanation(\"\"\"\n",
    "    Summary:\n",
    "      * Peak density per field.\n",
    "      \n",
    "    Notes:\n",
    "      * Pay attention to the axes of the X/Y coords as it can occur\n",
    "        that a limited number of fields are all on the same row/col\n",
    "        and therefore the axis dimensions will be pure noise.\n",
    "\"\"\")\n",
    "\n",
    "n_peaks_per_field = run.sigproc_v2.peaks().groupby(\"field_i\").count().field_peak_i\n",
    "hd(\"h2\", f\"<i>Mean pixels per peak:</i> {run.ims_import.dim**2 / np.mean(n_peaks_per_field):.1f}\")\n",
    "\n",
    "field_df = run.ims_import.metadata()[[\"field_i\", \"stage_x\", \"stage_y\"]].groupby(\"field_i\").mean().join(n_peaks_per_field)\n",
    "field_df[\"size\"] = field_df.field_peak_i * 0.03\n",
    "\n",
    "with z(_cols=2):\n",
    "    z.cols(\n",
    "        n_peaks_per_field,\n",
    "        f_title=\"# peaks per field\",\n",
    "        f_x_axis_label=\"field\",\n",
    "        f_y_axis_label=\"n_peaks\",\n",
    "    )\n",
    "    z.scat(\n",
    "        source=field_df, x=\"stage_x\", y=\"stage_y\", size=\"size\",\n",
    "        f_title=\"# peaks per field in stage X/Y coords.\",\n",
    "        f_x_axis_label=\"stage x (microns?)\",\n",
    "        f_y_axis_label=\"stage y (microns?)\",\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hd(\"h1\", f\"Movies\")\n",
    "displays.explanation(\"\"\"\n",
    "    Summary:\n",
    "      * Aligned movies.\n",
    "        - Left: unfiltered\n",
    "        - Right: with bandpass filter\n",
    "      \n",
    "    Filters applied:\n",
    "      * Aspect ratio (The circles that are drawn)\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "qdf = run.ims_import.qualities()\n",
    "\n",
    "for ch_i in range(run.ims_import.n_channels):\n",
    "    hd(\"h2\", f\"Channel {ch_i}\")\n",
    "\n",
    "    qdf = qdf[(qdf.field_i < run.sigproc_v2.n_fields) & (qdf.channel_i == ch_i)]\n",
    "    mean_qdf = qdf.groupby(\"field_i\").mean().reset_index().sort_values(\"quality\")\n",
    "    worst_fl_i = int(mean_qdf.iloc[0].field_i.astype(int))\n",
    "    median_fl_i = int(mean_qdf.iloc[len(mean_qdf) // 2].field_i.astype(int))\n",
    "\n",
    "    # std_qdf = qdf.groupby(\"field_i\").std().reset_index().sort_values(\"quality\")\n",
    "    # most_variable_fl_i = int(std_qdf.iloc[-1].field_i.astype(int))\n",
    "    \n",
    "    def movies(fl_i, description):\n",
    "        hd(\"h3\", f\"Field={fl_i} ({description})\")\n",
    "        top_unfilt = np.percentile(run.sigproc_v2.aln_unfilt_ims[0,ch_i,0], 99.9)\n",
    "        top_filt = np.percentile(run.sigproc_v2.aln_ims[0,ch_i,0], 99.9)\n",
    "        sigproc_v2_movie_from_df(run, fea_df, fl_i=fl_i, _cspan=(0, top_unfilt), draw_unfilt=True, draw_filt=True, scale_filt=top_unfilt/top_filt)\n",
    "        \n",
    "    movies(worst_fl_i, \"Worst quality\")\n",
    "    # movies(most_variable_fl_i, \"Most variable quality\")\n",
    "    movies(median_fl_i, \"Median quality\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_cycles = run.ims_import.n_cycles\n",
    "\n",
    "hd(\"h1\", f\"Pixel Intensity Distributions (by cycle @ 5 random fields)\")\n",
    "displays.explanation(\"\"\"\n",
    "    Summary:\n",
    "      * Distributions of pixels on 5 randomly chosen fields\n",
    "      \n",
    "    Filters applied:\n",
    "      * None\n",
    "    \n",
    "    Notes:\n",
    "      * The foreground pixels is somewhat arbitraily defined and\n",
    "        may pick up a considerable number of background pixels.\n",
    "      * The red line is set arbitrarily at 500 as a job-to-job reference.\n",
    "\"\"\")\n",
    "\n",
    "for ch_i in range(run.ims_import.n_channels):\n",
    "    hd(\"h2\", f\"Channel {ch_i}\")\n",
    "\n",
    "    n_samples = 10000\n",
    "    bg_samps = np.zeros((n_cycles, n_samples))\n",
    "    fg_samps = np.zeros((n_cycles, n_samples))\n",
    "    idx = np.arange(run.ims_import.dim**2)\n",
    "    cy_labels = [f\"cy {cy_i}\" for cy_i in range(n_cycles)]\n",
    "    for fl_i in utils.ispace(0, run.ims_import.n_fields, 5):\n",
    "        for cy_i in range(n_cycles):\n",
    "            im = run.ims_import.ims[fl_i, ch_i, cy_i]\n",
    "            bg_im, fg_mask = bg.background_extract(im, approximate_psf(), dilate=0)\n",
    "            _idx = data.subsample(idx[fg_mask.flatten()], n_samples)\n",
    "            bg_samps[cy_i, :] = data.subsample(bg_im.flatten(), n_samples)\n",
    "            fg_samps[cy_i, :] = im.flatten()[_idx]\n",
    "\n",
    "    with z(_cols=3):\n",
    "        top = np.nanpercentile(fg_samps, 99.9)\n",
    "        with z(_range_x=(0, top)):\n",
    "            z.distr(bg_samps, _vertical=500.0, _percentiles=(0, 25, 50, 75, 99.9), f_x_axis_label=\"Intensity\", f_y_axis_label=\"Cycle\", f_title=\"background pixels only\")\n",
    "            z.distr(fg_samps, _vertical=500.0, _percentiles=(0, 25, 50, 75, 99.9), f_x_axis_label=\"Intensity\", f_y_axis_label=\"Cycle\", f_title=\"foreground pixels only\")\n",
    "    \n",
    "        bg_medians = np.nanmedian(bg_samps, axis=1)\n",
    "        fg_medians = np.nanmedian(fg_samps, axis=1)\n",
    "        z.scat(\n",
    "            x=fg_medians,\n",
    "            y=bg_medians,\n",
    "            f_x_axis_label=\"FG Med. Intensity\",\n",
    "            f_y_axis_label=\"BG Med. Intensity\",\n",
    "            _label=cy_labels,\n",
    "        )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment in power analysis\n",
    "# from plaster.tools.image.coord import HW, ROI, WH, XY, YX, clip2d\n",
    "# def lf_power(im, dim_half=100):\n",
    "#     cen = YX(im.shape) / 2\n",
    "\n",
    "#     a = np.copy(im)\n",
    "#     a -= np.mean(a)\n",
    "#     af = np.fft.fft2(a)\n",
    "    \n",
    "#     peak_im = imops.gauss2_rho_form(1.0, 1.2, 1.2, 5.5, 5.5, 0.0, 0.0, 11)\n",
    "#     b = imops.convolve(a, peak_im)\n",
    "    \n",
    "#     # z.hist(b, _bins=(-400, 400, 200))\n",
    "#     lft = data.one_sided_nanstd(b.flatten(), mean=0.0, negative_side=True)\n",
    "#     b = np.where(b > 2*lft, np.nan, a)\n",
    "\n",
    "# # TODO:\n",
    "# # Where b in nan fill with noise\n",
    "\n",
    "#     with z(_cols=3, _cspan=(0, 400)):\n",
    "#         z.im(a)\n",
    "#         z.im(b)\n",
    "    \n",
    "#     power = np.abs(np.fft.fftshift(b))\n",
    "#     # power[power == 0] = 1\n",
    "\n",
    "#     dim = HW(dim_half * 2 + 1, dim_half * 2 + 1)\n",
    "#     roi = ROI(cen, dim, center=True)\n",
    "#     spec = power[roi]\n",
    "#     z.im(spec)\n",
    "# #     eigen = eigen_moments(im)\n",
    "# #     score = power.sum() / np.sqrt(eigen.sum())\n",
    "# #     return score\n",
    "\n",
    "# im = run.sigproc_v2.aln_unfilt_ims[0,0,0]\n",
    "# lf_power(im)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
