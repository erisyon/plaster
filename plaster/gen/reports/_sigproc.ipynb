{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: REMOVE ME!\n",
    "from plaster.tools.ipynb_helpers.displays import restart_kernel; restart_kernel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"MPLCONFIGDIR\"] = \"/tmp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import itertools\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "from IPython.display import HTML, display\n",
    "from plaster.run.calib.calib import RegPSF, approximate_psf\n",
    "from plaster.run.job import JobResult\n",
    "from plaster.run.plots import plots, plots_dev\n",
    "from plaster.run.plots.plots_sigproc import plot_psfs, circle_locs, sigproc_v2_im, sigproc_v2_movie_from_df, sigproc_v2_im_from_df\n",
    "from plaster.run.plots.plots_sigproc import wizard_xy_df, wizard_scat_df, wizard_raw_images\n",
    "from plaster.run.run import RunResult\n",
    "from plaster.run.sigproc_v2 import sigproc_v2_worker as worker\n",
    "from plaster.run.sigproc_v2.sigproc_v2_result import df_filter, radmat_from_df_filter, df_to_radmat, mean_non_dark_asr\n",
    "from plaster.run.sigproc_v2.synth import Synth\n",
    "from plaster.run.sigproc_v2 import bg\n",
    "from plaster.run.features import features\n",
    "from plaster.tools.image import imops\n",
    "from plaster.tools.image.coord import WH, XY, roi_shift, clip2d\n",
    "from plaster.tools.ipynb_helpers.displays import hd, movie, md\n",
    "from plaster.tools.log.log import error, debug\n",
    "from plaster.tools.schema import check\n",
    "from plaster.tools.utils import data\n",
    "from plaster.tools.utils import utils\n",
    "from plaster.tools.zap import zap\n",
    "from plaster.tools.zplots import zplots\n",
    "from plaster.tools.ipynb_helpers import displays\n",
    "z = zplots.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REMOVE ME\n",
    "from plaster.run.base_result import disable_disk_memoize_from_notebook\n",
    "disable_disk_memoize_from_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job = JobResult.from_context(dev_override=\"/erisyon/internal/jobs_folder/abbe7_1t\")\n",
    "run = job.sigproc_v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fea_df = features(run)\n",
    "n_peaks = fea_df.peak_i.max() + 1\n",
    "n_cycles = run.sigproc_v2.n_cycles\n",
    "sig = run.sigproc_v2.sig()\n",
    "\n",
    "hd(\"h1\", f\"Aspect ratios @ cycle=0, max all channels (a proxy for collisions)\")\n",
    "asr_thresh = run.sigproc_v2.asr_threshold()\n",
    "\n",
    "asr = fea_df.asr_cy0\n",
    "asr_mask = asr < asr_thresh\n",
    "n_keep = asr_mask.sum()\n",
    "\n",
    "hd(\"h2\", f\"Keep {100 * n_keep / n_peaks:.1f}%, Reject {100 * (n_peaks-n_keep) / n_peaks:.1f}%\")\n",
    "\n",
    "z.hist(asr, _bins=(1, 3, 200), _vertical=asr_thresh, f_title=\"Aspect-ratio @ cycle=0 Distr.\")\n",
    "\n",
    "fea_df = fea_df[asr_mask]\n",
    "# fea_df from here forward is aspect_ratio filtered\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "hd(\"h1\", f\"Radiometry\")\n",
    "\n",
    "cum_n_dark = np.zeros((n_cycles,))\n",
    "for cy_i in range(n_cycles):\n",
    "    cum_n_dark[cy_i] = (fea_df.run_len <= cy_i).sum()\n",
    "\n",
    "n_remainders = (fea_df.run_len == n_cycles).sum()\n",
    "n_first_drops = (fea_df.run_len == 1).sum()\n",
    "n_second_drops = (fea_df.run_len == 2).sum()\n",
    "\n",
    "hd(\"h2\", f\"Remainders: {100 * n_remainders / n_peaks:.1f}%\")\n",
    "hd(\"h2\", f\"Peaks that drop after first cycle: {100 * n_first_drops / n_peaks:.1f}%\")\n",
    "hd(\"h2\", f\"Peaks that drop after second cycle: {100 * n_second_drops / n_peaks:.1f}%\")\n",
    "\n",
    "# TODO: Make the following multi-channel\n",
    "with z(_cols=2):\n",
    "    z.hist(\n",
    "        fea_df.run_len,\n",
    "        _bins=(0, run.sigproc_v2.n_cycles, run.sigproc_v2.n_cycles),\n",
    "        f_title=\"Distr. of run lengths (ch 0)\",\n",
    "        f_x_axis_label=\"run length\",\n",
    "        f_y_axis_label=\"count\",\n",
    "    )\n",
    "\n",
    "    z.cols(\n",
    "        100 * cum_n_dark / n_peaks,\n",
    "        f_title=\"Cummulate # drops to dark (ch 0)\",\n",
    "        f_x_axis_label=\"cycle\",\n",
    "        f_y_axis_label=\"% peaks dark by cycle\",\n",
    "        _range_y=(0, 100)\n",
    "    )\n",
    "\n",
    "sig0 = sig[fea_df.peak_i, 0, :]\n",
    "bot, top = np.percentile(sig0, (50, 99))\n",
    "_, col_iz = np.indices(sig0.shape)\n",
    "sig0_run = np.where(col_iz < fea_df.run_len[:, None], sig0, np.nan)\n",
    "with utils.np_no_warn():\n",
    "    mins_diff = np.nanmin(np.diff(sig0_run, axis=1), axis=1)\n",
    "    mens = np.nanmean(sig0_run, axis=1)\n",
    "    non_monotonic_metric = mins_diff / mens\n",
    "    non_monotonic_threshold = -1\n",
    "    mask = non_monotonic_metric < non_monotonic_threshold\n",
    "    n_non_monotonic = mask.sum()\n",
    "\n",
    "    hd(\"h2\", f\"% Non-monotonic: {100 * n_non_monotonic / n_peaks:.1f}%\")\n",
    "\n",
    "    with z(_cols=2):\n",
    "        z.hist(\n",
    "            non_monotonic_metric,\n",
    "            _bins=(-6, 0, 200),\n",
    "            f_title=\"Distr. of non_monotonic_metric\",\n",
    "            f_x_axis_label=\"largest run_drop / run_mean\",\n",
    "            f_y_axis_label=\"count\",\n",
    "            _vertical=non_monotonic_threshold\n",
    "        )\n",
    "        \n",
    "        mdf = fea_df.sort_values([\"peak_i\"])[mask]\n",
    "        _hover_rows=dict(peak_i=mdf.peak_i, field_i=mdf.field_i)\n",
    "        z.im_clus(\n",
    "            sig0[mask],\n",
    "            _n_samples=500,\n",
    "            _cspan=(bot, top),\n",
    "            f_title=\"Sigfinicantly non-monotonic rows\",\n",
    "            f_x_axis_label=\"cycle\",\n",
    "            _hover_rows=_hover_rows,\n",
    "        )    \n",
    "\n",
    "for ch_i in range(run.ims_import.n_channels):\n",
    "    hd(\"h2\", f\"Channel {ch_i}\")\n",
    "\n",
    "    bot, top = np.percentile(sig, (50, 99))\n",
    "    with z(_cols=2, _size=500, _cspan=(bot, top)):\n",
    "        mdf = fea_df.sort_values([\"peak_i\"])\n",
    "        _hover_rows=dict(peak_i=mdf.peak_i, field_i=mdf.field_i)\n",
    "        axis_labels = dict(f_x_axis_label=\"cycle\", f_y_axis_label=\"peaks\")\n",
    "        z.im_clus(\n",
    "            sig[mdf.peak_i, ch_i, :],\n",
    "            _hover_rows=_hover_rows,\n",
    "            _n_samples=500,\n",
    "            f_title=\"Signal clustered by row\",\n",
    "            **axis_labels\n",
    "        )\n",
    "\n",
    "        mdf = fea_df.sort_values([\"sig_men\"])\n",
    "        z.im(\n",
    "            sig[mdf.peak_i, ch_i, :],\n",
    "            _hover_rows=_hover_rows,\n",
    "            f_title=\"Signal sorted by mean intensity\",\n",
    "            **axis_labels\n",
    "        )\n",
    "\n",
    "        mdf = fea_df.sample(1000).sort_values([\"run_len\", \"run_men\"])\n",
    "        z.im(\n",
    "            sig[mdf.peak_i, ch_i, :],\n",
    "            _hover_rows=dict(peak_i=mdf.peak_i, field_i=mdf.field_i),\n",
    "            f_title=\"Signal sorted by run_len then run_mean\",\n",
    "            **axis_labels\n",
    "        )\n",
    "\n",
    "        mdf = fea_df.sample(1000).sort_values([\"field_i\", \"run_len\", \"run_men\"])\n",
    "        z.im(\n",
    "            sig[mdf.peak_i, ch_i, :],\n",
    "            _hover_rows=dict(peak_i=mdf.peak_i, field_i=mdf.field_i),\n",
    "            f_title=\"Signal sorted by field_i then run_len then run_mean\",\n",
    "            **axis_labels\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hd(\"h1\", f\"Peak Feature Relationships\")\n",
    "mask = fea_df.run_len < n_cycles\n",
    "mdf = fea_df[mask]\n",
    "cols = [\"field_i\", \"aln_y\", \"aln_x\", \"flowcell_y\", \"flowcell_x\", \"radius\", \"run_len\", \"run_med\", \"run_iqr\", \"nei_med\", \"nei_iqr\", \"sig_med\", \"sig_iqr\", \"asr_cy0\"]\n",
    "mdf = mdf.sample(1000)\n",
    "with z(_cols=len(cols), _notools=True, _noaxes=True, _size=80, alpha=0.1):\n",
    "    for yi, col_y in enumerate(cols):\n",
    "        for xi, col_x in enumerate(cols):\n",
    "            f_title = col_x if yi == 0 else \"\"\n",
    "            f_y_axis_label = col_y if xi == 0 else \"\"\n",
    "            z.scat(x=mdf[col_x], y=mdf[col_y], f_title=f_title, f_y_axis_label=f_y_axis_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hd(\"h1\", f\"Calibration\")\n",
    "if \"calibration\" not in run.sigproc_v2.params:\n",
    "    print(\"No calibration was provded to this run\")\n",
    "else:\n",
    "    for ch_i in range(run.ims_import.n_channels):\n",
    "        hd(\"h2\", f\"Channel {ch_i}\")\n",
    "\n",
    "        with z(_cols=3, _size=250):\n",
    "            reg_psf = run.sigproc_v2.params.calibration.reg_psf(ch_i=ch_i)\n",
    "            check.t(reg_psf, RegPSF)\n",
    "            psf_ims = reg_psf.render()\n",
    "            plot_psfs(psf_ims, scale=3.0, f_title=f\"Regional PSF\", _noaxes=True, _notools=True, _zplots_context=z)\n",
    "\n",
    "            z.cols(\n",
    "                np.max(reg_psf.params[ch_i][:, :, 0:2], axis=2).flatten(),\n",
    "                f_x_axis_label=\"Region #\",\n",
    "                f_y_axis_label=\"peak size\",\n",
    "                f_title=\"Regional PSF peak size\",\n",
    "            )\n",
    "\n",
    "            illum = run.sigproc_v2.params.calibration.reg_illum().interp(ch_i)\n",
    "            z.im(1.0 / illum, f_title=\"Regional Illumination Balance Map\", _cspan=(0, 1.0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Add a \"recavlration\" for this experiment. If this experiment had been used as a calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: From here forward I'm trying to make sure that aspect ratio filter is in effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hd(\"h1\", f\"Signal distributions\")\n",
    "n_peaks_per_field = run.sigproc_v2.peaks().groupby(\"field_i\").count().field_peak_i\n",
    "n_peaks_max = np.max(n_peaks_per_field)\n",
    "n_fields = run.sigproc_v2.n_fields\n",
    "for ch_i in range(run.ims_import.n_channels):\n",
    "    hd(\"h2\", f\"Channel {ch_i}\")\n",
    "    \n",
    "    dark = run.sigproc_v2.dark_estimate(ch_i=ch_i)\n",
    "    sig = run.sigproc_v2.sig()[:, ch_i, :]\n",
    "    sig = sig.transpose(1, 0)\n",
    "    beta_est = np.median(sig[sig > dark])\n",
    "    sig_non_dark = np.where(sig > dark, sig, np.nan)\n",
    "\n",
    "    sig_non_dark_by_field = np.full((n_fields, n_peaks_max), np.nan)\n",
    "    for fl_i in range(n_fields):\n",
    "        _sig = run.sigproc_v2.sig(fields=fl_i)[:, ch_i, 0]\n",
    "        _sig_non_dark = np.where(_sig > dark, _sig, np.nan)\n",
    "        sig_non_dark_by_field[fl_i, 0:len(_sig_non_dark)] = _sig_non_dark\n",
    "\n",
    "    with z(_cols=3):\n",
    "        z.hist(\n",
    "            sig,\n",
    "            _vertical=beta_est,\n",
    "            f_x_axis_label=\"Signal\",\n",
    "            f_title=\"Signal distributions, all cycles, all fields\"\n",
    "        )\n",
    "        \n",
    "        z.hist(\n",
    "            sig[0, :],\n",
    "            _vertical=beta_est,\n",
    "            f_x_axis_label=\"Signal\",\n",
    "            f_title=\"Signal distributions, @ first cycle, all fields\"\n",
    "        )\n",
    "        \n",
    "        z.hist(\n",
    "            sig[-1, :],\n",
    "            _vertical=beta_est,\n",
    "            f_x_axis_label=\"Signal\",\n",
    "            f_title=\"Signal distributions, @ last cycle, all fields\"\n",
    "        )\n",
    "        \n",
    "        z.distr(\n",
    "            sig_non_dark,\n",
    "            _vertical=beta_est,\n",
    "            _percentiles=(0, 25, 50, 75, 99),\n",
    "            _nogrid=True,\n",
    "            f_x_axis_label=\"Signal\", f_y_axis_label=\"Cycle\",\n",
    "            f_title=\"Non-dark signal by cycle, all fields\"\n",
    "        )\n",
    "\n",
    "        z.distr(\n",
    "            sig_non_dark_by_field,\n",
    "            _vertical=beta_est,\n",
    "            _percentiles=(0, 25, 50, 75, 99),\n",
    "            _nogrid=True,\n",
    "            f_x_axis_label=\"Signal\", f_y_axis_label=\"Field\",\n",
    "            f_title=\"Non-dark signal @ cycle=0, by field\"\n",
    "        )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hd(\"h1\", f\"Peak density\")\n",
    "\n",
    "n_peaks_per_field = run.sigproc_v2.peaks().groupby(\"field_i\").count().field_peak_i\n",
    "hd(\"h2\", f\"<i>Mean pixels per peak:</i> {run.ims_import.dim**2 / np.mean(n_peaks_per_field):.1f}\")\n",
    "\n",
    "field_df = run.ims_import.metadata()[[\"field_i\", \"stage_x\", \"stage_y\"]].groupby(\"field_i\").mean().join(n_peaks_per_field)\n",
    "field_df[\"size\"] = field_df.field_peak_i * 0.03\n",
    "\n",
    "with z(_cols=2):\n",
    "    z.cols(\n",
    "        n_peaks_per_field,\n",
    "        f_title=\"# peaks per field\",\n",
    "        f_x_axis_label=\"field\",\n",
    "        f_y_axis_label=\"n_peaks\",\n",
    "    )\n",
    "    z.scat(\n",
    "        source=field_df, x=\"stage_x\", y=\"stage_y\", size=\"size\",\n",
    "        f_title=\"# peaks per field in stage X/Y coords.\",\n",
    "        f_x_axis_label=\"stage x\",\n",
    "        f_y_axis_label=\"stage y\",\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qdf = run.ims_import.qualities()\n",
    "qdf = qdf[(qdf.field_i < run.sigproc_v2.n_fields) & (qdf.channel_i == ch_i)]\n",
    "mean_qdf = qdf.groupby(\"field_i\").mean().reset_index().sort_values(\"quality\")\n",
    "median_fl_i = int(mean_qdf.iloc[len(mean_qdf) // 2].field_i.astype(int))\n",
    "\n",
    "hd(\"h1\", f\"All-cycles movie @ field={median_fl_i} (has median_quality)\")\n",
    "\n",
    "for ch_i in range(run.ims_import.n_channels):\n",
    "    hd(\"h2\", f\"Channel {ch_i}\")\n",
    "\n",
    "\n",
    "    df = run.sigproc_v2.fields__n_peaks__peaks__radmat(fields=median_fl_i)\n",
    "    dark = run.sigproc_v2.dark_estimate(ch_i=0, fields=median_fl_i)\n",
    "    max_asr = run.sigproc_v2.asr_threshold()\n",
    "    filt_df = df_filter(df, dark=dark, max_aspect_ratio=max_asr)\n",
    "    sigproc_v2_movie_from_df(run, filt_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hd(\"h1\", f\"All-fields movie @ cycle=0\")\n",
    "\n",
    "for ch_i in range(run.ims_import.n_channels):\n",
    "    hd(\"h2\", f\"Channel {ch_i}\")\n",
    "\n",
    "    ims = np.zeros((run.sigproc_v2.n_fields, run.ims_import.dim, run.ims_import.dim))\n",
    "    for fl_i in range(run.sigproc_v2.n_fields):\n",
    "        im = run.sigproc_v2.aln_ims[fl_i, ch_i, 0]\n",
    "        h, w = im.shape\n",
    "        ims[fl_i, 0:h, 0:w] = im\n",
    "\n",
    "    displays.movie(ims,\n",
    "        _labels=[\n",
    "            f\"fl_i:{fl_i} ch_i:{ch_i} cy_i: 0\"\n",
    "            for fl_i in range(run.sigproc_v2.n_fields)\n",
    "        ],\n",
    "        _duration=200,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_cycles = run.ims_import.n_cycles\n",
    "\n",
    "hd(\"h1\", f\"Pixel Intensity Distributions (by cycle @ 5 random fields)\")\n",
    "md(\"The <span style='color:red'>red line</span> is set arbitrarily at 500 for easier job to job refernce.\")\n",
    "\n",
    "for ch_i in range(run.ims_import.n_channels):\n",
    "    hd(\"h2\", f\"Channel {ch_i}\")\n",
    "\n",
    "    n_samples = 10000\n",
    "    bg_samps = np.zeros((n_cycles, n_samples))\n",
    "    fg_samps = np.zeros((n_cycles, n_samples))\n",
    "    idx = np.arange(run.ims_import.dim**2)\n",
    "    cy_labels = [f\"cy {cy_i}\" for cy_i in range(n_cycles)]\n",
    "    for fl_i in utils.ispace(0, run.ims_import.n_fields, 5):\n",
    "        for cy_i in range(n_cycles):\n",
    "            im = run.ims_import.ims[fl_i, ch_i, cy_i]\n",
    "            bg_im, fg_mask = bg.background_extract(im, approximate_psf(), dilate=0)\n",
    "            _idx = data.subsample(idx[fg_mask.flatten()], n_samples)\n",
    "            bg_samps[cy_i, :] = data.subsample(bg_im.flatten(), n_samples)\n",
    "            fg_samps[cy_i, :] = im.flatten()[_idx]\n",
    "\n",
    "    with z(_cols=3):\n",
    "        z.distr(bg_samps, _vertical=500.0, _percentiles=(0, 25, 50, 75, 99), f_x_axis_label=\"Intensity\", f_y_axis_label=\"Cycle\", f_title=\"background pixels only\")\n",
    "        z.distr(fg_samps, _vertical=500.0, _percentiles=(0, 25, 50, 75, 99), f_x_axis_label=\"Intensity\", f_y_axis_label=\"Cycle\", f_title=\"foreground pixels only\")\n",
    "    \n",
    "        bg_medians = np.nanmedian(bg_samps, axis=1)\n",
    "        fg_medians = np.nanmedian(fg_samps, axis=1)\n",
    "        z.scat(\n",
    "            x=fg_medians,\n",
    "            y=bg_medians,\n",
    "            f_x_axis_label=\"FG Med. Inentsity\", f_y_axis_label=\"BG Med. Inentsity\",\n",
    "            _label=cy_labels\n",
    "        )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hd(\"h1\", f\"Field Quality\")\n",
    "for ch_i in range(run.ims_import.n_channels):\n",
    "    hd(\"h2\", f\"Channel {ch_i}\")\n",
    "    qdf = run.ims_import.qualities()\n",
    "    qdf = qdf[(qdf.field_i < run.sigproc_v2.n_fields) & (qdf.channel_i == ch_i)].sort_values([\"quality\"])\n",
    "    z.hist(qdf.quality, _size_x=800, _size_y=150, f_title=f\"Quality distribution\")\n",
    "\n",
    "    row_iz = utils.ispace(0, len(qdf), 3)\n",
    "\n",
    "    # COMBINE all images for common percentile calculations\n",
    "    ims = np.concatenate([\n",
    "        run.sigproc_v2.aln_ims[row.field_i, row.channel_i, row.cycle_i].flatten()\n",
    "        for row in qdf.iloc[row_iz].itertuples()\n",
    "    ])\n",
    "    bot, top = np.percentile(ims, (50, 99.9))\n",
    "\n",
    "    # SHOW example of worst, median, and best all using the same cspan\n",
    "    hd(\"h3\", f\"Examples of frames by quality\")\n",
    "    with z(_cols=3, _cspan=(bot, top)):\n",
    "        names = (\"worst\", \"median\", \"best\")\n",
    "        for name, row in zip(names, qdf.iloc[row_iz].itertuples()):\n",
    "            z.im(run.sigproc_v2.aln_ims[row.field_i, row.channel_i, row.cycle_i], f_title=f\"{name} fl_i={row.field_i} cy_i={row.cycle_i}, qual={row.quality:.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hd(\"h1\", f\"Field Alignment\")\n",
    "field_df = run.sigproc_v2.fields().copy()\n",
    "field_df[\"alignment\"] = np.sqrt(field_df.aln_x**2 + field_df.aln_y**2)\n",
    "alignment = field_df.groupby(\"field_i\").alignment.max().values\n",
    "z.cols(alignment, f_x_axis_label=\"field_i\", f_y_axis_label=\"n_pixels\", f_title=\"Max. alignment distance by field\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
