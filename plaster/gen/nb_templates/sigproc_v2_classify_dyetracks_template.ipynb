{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @REMOVE-FROM-TEMPLATE\n",
    "from plaster.tools.ipynb_helpers.displays import restart_kernel; restart_kernel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @IMPORT-MERGE\n",
    "import os\n",
    "os.environ[\"MPLCONFIGDIR\"] = \"/tmp\"\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import cv2\n",
    "import random\n",
    "from scipy.stats import lognorm\n",
    "from IPython.display import HTML, display\n",
    "from plaster.tools.log.log import error, debug\n",
    "from plaster.run.job import JobResult\n",
    "from plaster.run.run import RunResult\n",
    "from plaster.run.sigproc_v2 import sigproc_v2_worker as worker\n",
    "from plaster.run.sigproc_v2.sigproc_v2_result import df_filter, radmat_from_df_filter, df_to_radmat\n",
    "from plaster.run.plots import plots, plots_dev\n",
    "from plaster.run.plots.plots_sigproc import plot_psfs, circle_locs, sigproc_v2_im, sigproc_v2_movie_from_df, sigproc_v2_im_from_df\n",
    "from plaster.run.plots.plots_sigproc import wizard_xy_df, wizard_scat_df, wizard_raw_images\n",
    "from plaster.run.sigproc_v2.synth import Synth\n",
    "from plaster.tools.image.coord import WH, XY, roi_shift, clip2d\n",
    "from plaster.tools.utils import data\n",
    "from plaster.tools.zplots import zplots\n",
    "from plaster.tools.schema import check\n",
    "from plaster.tools.image import imops\n",
    "from plaster.tools.zap import zap\n",
    "from plaster.tools.utils import utils\n",
    "from plaster.tools.utils import data\n",
    "from plaster.run.calib.calib import Calib\n",
    "from plaster.tools.ipynb_helpers.displays import hd, movie\n",
    "z = zplots.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @REMOVE-FROM-TEMPLATE\n",
    "from plumbum import local\n",
    "job = JobResult(\"/erisyon/internal/jobs_folder/abbe7_1t\")\n",
    "run = job.runs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "which_nn_v2 = \"nn_v2\"\n",
    "\n",
    "n_channels = run.sigproc_v2.n_channels\n",
    "n_cycles = run.sigproc_v2.n_cycles\n",
    "dyemat = run[which_nn_v2]._dyemat\n",
    "dyepeps = run[which_nn_v2]._dyepeps\n",
    "calls_df = run[which_nn_v2].calls(\"sigproc\")\n",
    "sigproc_df = run.sigproc_v2.fields__n_peaks__peaks__radmat()\n",
    "\n",
    "beta = run[which_nn_v2].params.gain_model.channels[0].beta\n",
    "row_k_score_factor = run[which_nn_v2].params.row_k_score_factor\n",
    "row_k_score_factor = run[which_nn_v2].params.row_k_score_factor\n",
    "row_k_sigma = run[which_nn_v2].params.gain_model.row_k_sigma\n",
    "run_row_k_fit = run[which_nn_v2].params.run_row_k_fit\n",
    "debug(beta, row_k_score_factor, row_k_sigma, run_row_k_fit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show parameter distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_dyts = dyemat.shape[0]\n",
    "with z(_cols=3, _remove_nan=True, _size=300):\n",
    "    pred_dyt_iz = calls_df.dyt_i\n",
    "    \n",
    "    z.hist(calls_df.k, _bins=(0, 4, 200), f_title=\"k\", f_x_axis_label=\"row_k\")\n",
    "    z.hist(pred_dyt_iz, _bins=(0, n_dyts, n_dyts), f_title=\"dyt_i, ie cy-off (excl. cy=0 and last)\", f_x_axis_label=\"cy assign\")\n",
    "    z.hist(calls_df.dyt_score, _bins=(0, 1.0, 300), f_title=\"dyt_score\", f_x_axis_label=\"dyt_score\")\n",
    "    z.hist(calls_df.score, _bins=(0, 1.0, 300), f_title=\"scores\", f_x_axis_label=\"score\")\n",
    "    \n",
    "    z.hist(np.nan_to_num(calls_df.logp_dyt), _bins=(-600, -250, 100), f_title=\"logp_dyt\", f_x_axis_label=\"logp_dyt\")\n",
    "    z.hist(np.nan_to_num(calls_df.logp_k), _bins=(-50, 0, 100), f_title=\"logp_k\", f_x_axis_label=\"logp_k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_filter(calls_df, sigproc_df, n_subsample_peaks=None, **kwargs):\n",
    "    \"\"\"\n",
    "    Combine the dataframes from sigproc and nn_v2\n",
    "    so that we can filter on both column sets.\n",
    "    \"\"\"    \n",
    "    if n_subsample_peaks is not None:\n",
    "        calls_df = calls_df.sample(n_subsample_peaks)\n",
    "    \n",
    "    joined_df = calls_df.set_index(\"peak_i\").join(\n",
    "        sigproc_df.set_index(\"peak_i\")\n",
    "    ).reset_index().rename(columns=dict(index=\"peak_i\"))\n",
    "\n",
    "    # REMOVE anything assigned to a dyt that goes dark after 0th cycle\n",
    "    zero_cy_1_dyt_iz = np.argwhere(dyemat[:, 1] == 0).flatten()\n",
    "    for remove_cy_i in zero_cy_1_dyt_iz:\n",
    "        joined_df = joined_df[joined_df.dyt_i != remove_cy_i]\n",
    "\n",
    "    radmat, filt_sig_df = radmat_from_df_filter(joined_df, channel_i=0, return_df=True, **kwargs)\n",
    "\n",
    "    keep_peaks_iz = filt_sig_df.peak_i.unique()\n",
    "    filt_cal_df = calls_df.set_index(\"peak_i\").loc[keep_peaks_iz].reset_index()\n",
    "    \n",
    "    n_rows = radmat.shape[0]\n",
    "    keep_rows = np.ones((n_rows,), dtype=bool) #filt_cal_df.score > 0.20\n",
    "    \n",
    "    # TODO: Try some other filtering?\n",
    "\n",
    "    return radmat[keep_rows], filt_cal_df[keep_rows], joined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filt_radmat, filt_cal_df, joined_df = apply_filter(calls_df, sigproc_df, max_k=1.5, monotonic=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filt_balanced = filt_radmat / filt_cal_df.k[:, None]\n",
    "stack_im = np.hstack((filt_radmat, filt_balanced, 5000*dyemat[filt_cal_df.dyt_i]))\n",
    "\n",
    "with z(_cspan=(0, 20000), _size=800):\n",
    "    im = stack_im[np.argsort(filt_cal_df.dyt_i)]\n",
    "    z.im(im[0::5], f_title=f\"Raw vs. k-balanced, filter nul assignments, sorted by pred_dyt_i\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary of counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COUNT dyts of various counts\n",
    "one_count_dyt_iz = np.argwhere(np.all(dyemat <= 1, axis=1)).flatten()\n",
    "two_count_dyt_iz = np.argwhere(np.all(dyemat <= 2, axis=1) & np.any(dyemat == 2, axis=1)).flatten()\n",
    "three_count_dyt_iz = np.argwhere(np.all(dyemat <= 3, axis=1) & np.any(dyemat == 3, axis=1)).flatten()\n",
    "\n",
    "one_rows = np.isin(calls_df.dyt_i, one_count_dyt_iz)\n",
    "two_rows = np.isin(calls_df.dyt_i, two_count_dyt_iz)\n",
    "three_rows = np.isin(calls_df.dyt_i, three_count_dyt_iz)\n",
    "\n",
    "n_rows_total = sigproc_df.peak_i.max() + 1\n",
    "n_rows_keep = len(calls_df)\n",
    "n_ones = one_rows.sum()\n",
    "n_twos = two_rows.sum()\n",
    "n_threes = three_rows.sum()\n",
    "\n",
    "print(f\"\"\"\n",
    "n_rows_total {n_rows_total:>8d}\n",
    "n_rows_keep  {n_rows_keep:>8d} {100 * n_rows_keep / n_rows_total:>5.1f}%\n",
    "n_ones       {n_ones:>8d} {100 * n_ones / n_rows_total:>5.1f}%\n",
    "n_twos       {n_twos:>8d} {100 * n_twos / n_rows_total:>5.1f}%\n",
    "n_threes     {n_threes:>8d} {100 * n_threes / n_rows_total:>5.1f}%\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distributions of counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run[which_nn_v2].params.gain_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From abbe7_1t\n",
    "# beta: 4444.0\n",
    "# sigma: 0.15\n",
    "\n",
    "orig_beta = run[which_nn_v2].params.gain_model.channels[0].beta\n",
    "orig_sigma = run[which_nn_v2].params.gain_model.channels[0].sigma\n",
    "\n",
    "beta = orig_beta #* 0.95\n",
    "sigma = orig_sigma #* 1.30\n",
    "debug(beta, sigma)\n",
    "\n",
    "with z(_cols=4, _size=250):\n",
    "    for cnt in range(1, 3):\n",
    "        d = filt_balanced[dyemat[filt_cal_df.dyt_i] == cnt]\n",
    "        model_samples = lognorm.rvs(scale=beta * cnt, s=sigma, size=len(d))\n",
    "        with z(_merge=True, _bins=(0, 15_000, 500), alpha=0.3, f_title=f\"cnt={cnt}\"):\n",
    "            z.hist(d, color=\"blue\")\n",
    "            z.hist(model_samples, color=\"red\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examine raw movies with highlights of row that are highly variable\n",
    "## Where \"highly variable\" means what?\n",
    "* Large displacement of k?\n",
    "* Large variance of the 0, 1, or 2 count areas?\n",
    "* Low score?\n",
    "* Low SNR?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df[\"clip_snr\"] = joined_df.signal.clip(lower=0) / joined_df.noise\n",
    "joined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (joined_df.signal > 0) & (joined_df.signal < 7000)\n",
    "\n",
    "pfit = np.polyfit(x=joined_df.signal.values[mask], y=joined_df.clip_snr.values[mask], deg=1)\n",
    "p = np.poly1d(pfit)\n",
    "joined_df[\"corr_snr\"] = (joined_df.clip_snr.values - p(joined_df.signal)) / p(joined_df.signal)\n",
    "\n",
    "# TODO: Make corr_snr a pseudo-zscore not a simple value\n",
    "# No this is wrong\n",
    "\n",
    "# df = (\n",
    "#     joined_df[joined_df.cycle_i == 1][[\"peak_i\", \"corr_snr\"]]\n",
    "#     .set_index(\"peak_i\")\n",
    "#     .rename(columns=dict(corr_snr=\"cy1_corr_snr\"))\n",
    "#     .join(joined_df.set_index(\"peak_i\"))\n",
    "#     .reset_index(drop=True)\n",
    "# )\n",
    "\n",
    "with z(_cols=3):\n",
    "    with z(_merge=True):\n",
    "        z.scat(x=df.signal.values, y=df.clip_snr.values, _n_samples=1000, alpha=0.5)\n",
    "        x = np.linspace(0, 10000)\n",
    "        z.line(x=x, y=p(x), color=\"red\")\n",
    "#         z.line(x=x, y=p(1.5*x), color=\"red\")\n",
    "#         z.line(x=x, y=p(0.5*x), color=\"red\")\n",
    "\n",
    "#     z.hist(df.corr_snr[df.clip_snr > 0])\n",
    "#     z.hist(df.cy1_corr_snr)\n",
    "    z.hist(df.score)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "field_df = df[df.field_i == 1]\n",
    "\n",
    "#show_df = field_df[field_df.k > 1.3].reset_index()\n",
    "#show_df = field_df[field_df.k < 0.7].reset_index()\n",
    "#show_df = field_df[(0.9 < field_df.k) & (field_df.k < 1.1)].reset_index()\n",
    "#show_df = field_df[field_df.k > 1.3].reset_index()\n",
    "\n",
    "#show_df = field_df[field_df.snr > 1.3].reset_index()\n",
    "#show_df = field_df[  np.abs(field_df.cy1_corr_snr) > 0.4 ].reset_index()\n",
    "show_df = field_df[ field_df.score < 0.1 ].reset_index()\n",
    "\n",
    "sigproc_v2_movie_from_df(\n",
    "    run, show_df, fg_only=True,\n",
    "    _cspan=(0, 500), outer_radius=2,\n",
    "    yx=(100, 200), hw=(200, 200)\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
