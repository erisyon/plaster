{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>Jupyter.notebook.kernel.restart()</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# @REMOVE-FROM-TEMPLATE\n",
    "from plaster.tools.ipynb_helpers.displays import restart_kernel; restart_kernel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <a href=\"https://bokeh.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"1001\">Loading BokehJS ...</span>\n",
       "    </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "\n",
       "  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "  var JS_MIME_TYPE = 'application/javascript';\n",
       "  var HTML_MIME_TYPE = 'text/html';\n",
       "  var EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
       "  var CLASS_NAME = 'output_bokeh rendered_html';\n",
       "\n",
       "  /**\n",
       "   * Render data to the DOM node\n",
       "   */\n",
       "  function render(props, node) {\n",
       "    var script = document.createElement(\"script\");\n",
       "    node.appendChild(script);\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when an output is cleared or removed\n",
       "   */\n",
       "  function handleClearOutput(event, handle) {\n",
       "    var cell = handle.cell;\n",
       "\n",
       "    var id = cell.output_area._bokeh_element_id;\n",
       "    var server_id = cell.output_area._bokeh_server_id;\n",
       "    // Clean up Bokeh references\n",
       "    if (id != null && id in Bokeh.index) {\n",
       "      Bokeh.index[id].model.document.clear();\n",
       "      delete Bokeh.index[id];\n",
       "    }\n",
       "\n",
       "    if (server_id !== undefined) {\n",
       "      // Clean up Bokeh references\n",
       "      var cmd = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
       "      cell.notebook.kernel.execute(cmd, {\n",
       "        iopub: {\n",
       "          output: function(msg) {\n",
       "            var id = msg.content.text.trim();\n",
       "            if (id in Bokeh.index) {\n",
       "              Bokeh.index[id].model.document.clear();\n",
       "              delete Bokeh.index[id];\n",
       "            }\n",
       "          }\n",
       "        }\n",
       "      });\n",
       "      // Destroy server and session\n",
       "      var cmd = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
       "      cell.notebook.kernel.execute(cmd);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when a new output is added\n",
       "   */\n",
       "  function handleAddOutput(event, handle) {\n",
       "    var output_area = handle.output_area;\n",
       "    var output = handle.output;\n",
       "\n",
       "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
       "    if ((output.output_type != \"display_data\") || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n",
       "      return\n",
       "    }\n",
       "\n",
       "    var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
       "      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
       "      // store reference to embed id on output_area\n",
       "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "    }\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "      var bk_div = document.createElement(\"div\");\n",
       "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "      var script_attrs = bk_div.children[0].attributes;\n",
       "      for (var i = 0; i < script_attrs.length; i++) {\n",
       "        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "        toinsert[toinsert.length - 1].firstChild.textContent = bk_div.children[0].textContent\n",
       "      }\n",
       "      // store reference to server id on output_area\n",
       "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function register_renderer(events, OutputArea) {\n",
       "\n",
       "    function append_mime(data, metadata, element) {\n",
       "      // create a DOM node to render to\n",
       "      var toinsert = this.create_output_subarea(\n",
       "        metadata,\n",
       "        CLASS_NAME,\n",
       "        EXEC_MIME_TYPE\n",
       "      );\n",
       "      this.keyboard_manager.register_events(toinsert);\n",
       "      // Render to node\n",
       "      var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "      render(props, toinsert[toinsert.length - 1]);\n",
       "      element.append(toinsert);\n",
       "      return toinsert\n",
       "    }\n",
       "\n",
       "    /* Handle when an output is cleared or removed */\n",
       "    events.on('clear_output.CodeCell', handleClearOutput);\n",
       "    events.on('delete.Cell', handleClearOutput);\n",
       "\n",
       "    /* Handle when a new output is added */\n",
       "    events.on('output_added.OutputArea', handleAddOutput);\n",
       "\n",
       "    /**\n",
       "     * Register the mime type and append_mime function with output_area\n",
       "     */\n",
       "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "      /* Is output safe? */\n",
       "      safe: true,\n",
       "      /* Index of renderer in `output_area.display_order` */\n",
       "      index: 0\n",
       "    });\n",
       "  }\n",
       "\n",
       "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
       "  if (root.Jupyter !== undefined) {\n",
       "    var events = require('base/js/events');\n",
       "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  \n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  var NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    var el = document.getElementById(\"1001\");\n",
       "    if (el != null) {\n",
       "      el.textContent = \"BokehJS is loading...\";\n",
       "    }\n",
       "    if (root.Bokeh !== undefined) {\n",
       "      if (el != null) {\n",
       "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) {\n",
       "        if (callback != null)\n",
       "          callback();\n",
       "      });\n",
       "    } finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.debug(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(css_urls, js_urls, callback) {\n",
       "    if (css_urls == null) css_urls = [];\n",
       "    if (js_urls == null) js_urls = [];\n",
       "\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = css_urls.length + js_urls.length;\n",
       "\n",
       "    function on_load() {\n",
       "      root._bokeh_is_loading--;\n",
       "      if (root._bokeh_is_loading === 0) {\n",
       "        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n",
       "        run_callbacks()\n",
       "      }\n",
       "    }\n",
       "\n",
       "    function on_error() {\n",
       "      console.error(\"failed to load \" + url);\n",
       "    }\n",
       "\n",
       "    for (var i = 0; i < css_urls.length; i++) {\n",
       "      var url = css_urls[i];\n",
       "      const element = document.createElement(\"link\");\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.rel = \"stylesheet\";\n",
       "      element.type = \"text/css\";\n",
       "      element.href = url;\n",
       "      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n",
       "      document.body.appendChild(element);\n",
       "    }\n",
       "\n",
       "    const hashes = {\"https://cdn.bokeh.org/bokeh/release/bokeh-2.1.1.min.js\": \"kLr4fYcqcSpbuI95brIH3vnnYCquzzSxHPU6XGQCIkQRGJwhg0StNbj1eegrHs12\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.1.1.min.js\": \"xIGPmVtaOm+z0BqfSOMn4lOR6ciex448GIKG4eE61LsAvmGj48XcMQZtKcE/UXZe\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.1.1.min.js\": \"Dc9u1wF/0zApGIWoBbH77iWEHtdmkuYWG839Uzmv8y8yBLXebjO9ZnERsde5Ln/P\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-2.1.1.min.js\": \"cT9JaBz7GiRXdENrJLZNSC6eMNF3nh3fa5fTF51Svp+ukxPdwcU5kGXGPBgDCa2j\"};\n",
       "\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      var element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      if (url in hashes) {\n",
       "        element.crossOrigin = \"anonymous\";\n",
       "        element.integrity = \"sha384-\" + hashes[url];\n",
       "      }\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "  };\n",
       "\n",
       "  function inject_raw_css(css) {\n",
       "    const element = document.createElement(\"style\");\n",
       "    element.appendChild(document.createTextNode(css));\n",
       "    document.body.appendChild(element);\n",
       "  }\n",
       "\n",
       "  \n",
       "  var js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-2.1.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.1.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.1.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-2.1.1.min.js\"];\n",
       "  var css_urls = [];\n",
       "  \n",
       "\n",
       "  var inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    function(Bokeh) {\n",
       "    \n",
       "    \n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    \n",
       "    if (root.Bokeh !== undefined || force === true) {\n",
       "      \n",
       "    for (var i = 0; i < inline_js.length; i++) {\n",
       "      inline_js[i].call(root, root.Bokeh);\n",
       "    }\n",
       "    if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      var cell = $(document.getElementById(\"1001\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(css_urls, js_urls, function() {\n",
       "      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.bokehjs_load.v0+json": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  \n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  var NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    var el = document.getElementById(\"1001\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error() {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (var i = 0; i < css_urls.length; i++) {\n      var url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    const hashes = {\"https://cdn.bokeh.org/bokeh/release/bokeh-2.1.1.min.js\": \"kLr4fYcqcSpbuI95brIH3vnnYCquzzSxHPU6XGQCIkQRGJwhg0StNbj1eegrHs12\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.1.1.min.js\": \"xIGPmVtaOm+z0BqfSOMn4lOR6ciex448GIKG4eE61LsAvmGj48XcMQZtKcE/UXZe\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.1.1.min.js\": \"Dc9u1wF/0zApGIWoBbH77iWEHtdmkuYWG839Uzmv8y8yBLXebjO9ZnERsde5Ln/P\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-2.1.1.min.js\": \"cT9JaBz7GiRXdENrJLZNSC6eMNF3nh3fa5fTF51Svp+ukxPdwcU5kGXGPBgDCa2j\"};\n\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      if (url in hashes) {\n        element.crossOrigin = \"anonymous\";\n        element.integrity = \"sha384-\" + hashes[url];\n      }\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  \n  var js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-2.1.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.1.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.1.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-2.1.1.min.js\"];\n  var css_urls = [];\n  \n\n  var inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    function(Bokeh) {\n    \n    \n    }\n  ];\n\n  function run_inline_js() {\n    \n    if (root.Bokeh !== undefined || force === true) {\n      \n    for (var i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\n    if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      var cell = $(document.getElementById(\"1001\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# @IMPORT-MERGE\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import cv2\n",
    "from plaster.tools.log.log import error, debug\n",
    "from plaster.run.job import JobResult\n",
    "from plaster.run.run import RunResult\n",
    "from plaster.run.sigproc_v2 import sigproc_v2_worker as worker\n",
    "from plaster.run import plots\n",
    "from plaster.run.sigproc_v2.synth import Synth\n",
    "from plaster.tools.image.coord import WH, XY, roi_shift, clip2d\n",
    "from plaster.tools.utils import data\n",
    "from plaster.tools.zplots import zplots\n",
    "from plaster.tools.schema import check\n",
    "from plaster.tools.image import imops\n",
    "from plaster.tools.zap import zap\n",
    "from plaster.tools.utils import utils\n",
    "from plaster.tools.calibration.calibration import Calibration\n",
    "z = zplots.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @REMOVE-FROM-TEMPLATE\n",
    "from plumbum import local\n",
    "job = JobResult(\"/erisyon/internal/jobs_folder/val_calib\")\n",
    "run = job.runs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = run.ims_import.metadata()\n",
    "# df = df[[\"cycle_i\", \"pfs_offset\", \"stage_z\"]]\n",
    "# with z(_cols=2, f_x_axis_label=\"Cycle\"):\n",
    "#     z.scat(x=df.cycle_i, y=df.pfs_offset, f_y_axis_label=\"PFS Offset\")\n",
    "#     z.scat(x=df.cycle_i, y=df.stage_z, f_y_axis_label=\"State Z\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze Drops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "need at least one array to concatenate",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-cd409dd3201b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_cols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m     \u001b[0m_analyze_loss_cycle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcy_i\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m     \u001b[0m_analyze_loss_cycle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcy_i\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;31m#     _analyze_loss_cycle_foo(cy_i=5)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-cd409dd3201b>\u001b[0m in \u001b[0;36m_analyze_loss_cycle\u001b[0;34m(cy_i, n_samples)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_analyze_loss_cycle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcy_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     \u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msnr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpeaks_lost_on_cycle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mch_i\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcy_i\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcy_i\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0msig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-cd409dd3201b>\u001b[0m in \u001b[0;36mpeaks_lost_on_cycle\u001b[0;34m(run, ch_i, cy_i, snr_thresh)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mn_cycles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigproc_v2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_cycles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0msig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigproc_v2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignal_radmat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchannel_i\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0msnr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigproc_v2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msnr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchannel_i\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0msnr_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msnr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcy_i\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0msnr_thresh\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/erisyon/plaster/plaster/run/sigproc_v2/sigproc_v2_result.py\u001b[0m in \u001b[0;36msignal_radmat\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    253\u001b[0m         return self.flat_if_requested(\n\u001b[1;32m    254\u001b[0m             np.nan_to_num(\n\u001b[0;32m--> 255\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_ndarray_prop_from_all_fields\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"radmat\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m             ),\n\u001b[1;32m    257\u001b[0m             \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/erisyon/plaster/plaster/run/sigproc_v2/sigproc_v2_result.py\u001b[0m in \u001b[0;36m_load_ndarray_prop_from_all_fields\u001b[0;34m(self, prop, vstack)\u001b[0m\n\u001b[1;32m    220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mvstack\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m                 \u001b[0mval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m                 \u001b[0mval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mvstack\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m/venv/.venv/lib/python3.8/site-packages/numpy/core/shape_base.py\u001b[0m in \u001b[0;36mvstack\u001b[0;34m(tup)\u001b[0m\n\u001b[1;32m    281\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m         \u001b[0marrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0marrs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 283\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_nx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mconcatenate\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: need at least one array to concatenate"
     ]
    }
   ],
   "source": [
    "def peaks_lost_on_cycle(run, ch_i, cy_i, snr_thresh=5.0):\n",
    "    \"\"\"\n",
    "    If cy_i is None then it finds remainders\n",
    "    \"\"\"\n",
    "    n_cycles = run.sigproc_v2.n_cycles\n",
    "\n",
    "    sig = run.sigproc_v2.signal_radmat()[:, channel_i]\n",
    "    snr = run.sigproc_v2.snr()[:, channel_i]\n",
    "    snr_mask = snr[:, cy_i] > snr_thresh\n",
    "\n",
    "    relative_to_cy_0 = utils.np_safe_divide(sig, sig[:, 0][:, None])\n",
    "    if cy_i is None or cy_i >= n_cycles-1:\n",
    "        sig_mask = np.all(relative_to_cy_0 > 0.5, axis=1)\n",
    "    else:\n",
    "        sig_mask = np.all(relative_to_cy_0[:, 0:cy_i+1] > 0.7, axis=1) & np.all(relative_to_cy_0[:, cy_i+1:] < 0.1, axis=1)\n",
    "\n",
    "    mask = snr_mask & sig_mask\n",
    "    return run.sigproc_v2.peaks()[mask].reset_index(drop=True), sig[mask], snr[mask]\n",
    "\n",
    "def draw_traces(df, sig):\n",
    "    n_cycles = sig.shape[1]\n",
    "    xs = np.tile(np.arange(n_cycles), (len(df), 1))\n",
    "    ys = sig\n",
    "    xs = np.repeat(xs, 2, axis=1)\n",
    "    ys = np.repeat(sig, 2, axis=1)\n",
    "    xs[:, 1::2] = xs[:, 0::2] + 1\n",
    "    z.multi_line(xs=xs, ys=ys)\n",
    "\n",
    "def fit_gaussian_peaks(run, df, ch_i, cy_i, mea=9):\n",
    "    n_rows = len(df)\n",
    "    fit_prms = np.full((n_rows, 7), np.nan)\n",
    "    fit_stds = np.full((n_rows, 7), np.nan)\n",
    "    fit_sigs = np.full((n_rows,), np.nan)\n",
    "    fit_nois = np.full((n_rows,), np.nan)\n",
    "\n",
    "    for row_i, row in enumerate(df.itertuples()):\n",
    "        im = run.sigproc_v2.aln_ims[row.field_i, ch_i, cy_i]\n",
    "\n",
    "        im = imops.crop(im, off=XY(row.aln_x, row.aln_y), dim=WH(mea, mea), center=True)\n",
    "        if im.shape != (mea, mea):\n",
    "            continue\n",
    "\n",
    "        fit_prm, fit_var = imops.fit_gauss2(im)\n",
    "\n",
    "        kernel = imops.gauss2_rho_form(*fit_prm)\n",
    "        hat = np.ones(kernel.shape)  # Improve\n",
    "        sig, noi = _peak_radiometry(im, kernel / kernel.sum(), hat, allow_non_unity_psf_kernel=True)\n",
    "\n",
    "        fit_prms[row_i] = fit_prm\n",
    "        fit_stds[row_i] = np.sqrt(np.array(fit_var))\n",
    "        fit_sigs[row_i] = sig\n",
    "        fit_nois[row_i] = noi\n",
    "\n",
    "    return fit_prms, fit_stds, fit_sigs, fit_nois\n",
    "\n",
    "n_cycles = run.sigproc_v2.n_cycles\n",
    "\n",
    "def _analyze_loss_cycle(cy_i, n_samples=200):\n",
    "    df, sig, snr = peaks_lost_on_cycle(run, ch_i=0, cy_i=cy_i)\n",
    "    df = df.sample(n_samples)\n",
    "    sig = sig[df.index]\n",
    "    snr = snr[df.index]\n",
    "    draw_traces(df, snr)\n",
    "\n",
    "    fit_prms, fit_stds, fit_sigs, fit_nois = fit_gaussian_peaks(run, df, ch_i=0, cy_i=cy_i)\n",
    "    z.hist(sig[:, cy_i], _bins=np.linspace(0, 20_000), _range_y=(0, 40), f_title=\"sig\")\n",
    "    z.hist(fit_sigs, _bins=np.linspace(0, 20_000), _range_y=(0, 40), f_title=\"fit_sig\")\n",
    "    z.hist(fit_prms[:, 1], _bins=np.linspace(0, 5), _range_y=(0, 40), f_title=\"fit_std_x\")\n",
    "\n",
    "# def _analyze_loss_cycle_foo(cy_i, n_samples=200):\n",
    "#     df, sig, snr = peaks_lost_on_cycle(run, ch_i=0, cy_i=cy_i)\n",
    "#     df = df.sample(n_samples)\n",
    "#     sig = sig[df.index]\n",
    "#     snr = snr[df.index]\n",
    "#     draw_traces(df, snr)\n",
    "\n",
    "#     fit_prms, fit_stds, fit_sigs, fit_nois = fit_gaussian_peaks(run, df, ch_i=0, cy_i=cy_i-1)\n",
    "#     z.hist(sig[:, cy_i], _bins=np.linspace(0, 20_000), _range_y=(0, 40), f_title=\"sig\")\n",
    "#     z.hist(fit_sigs, _bins=np.linspace(0, 20_000), _range_y=(0, 40), f_title=\"fit_sig\")\n",
    "#     z.hist(fit_prms[:, 1], _bins=np.linspace(0, 5), _range_y=(0, 40), f_title=\"fit_std_x\")\n",
    "\n",
    "with z(_cols=4, _size=200):\n",
    "    _analyze_loss_cycle(cy_i=4)\n",
    "    _analyze_loss_cycle(cy_i=5)\n",
    "#     _analyze_loss_cycle_foo(cy_i=5)\n",
    "    _analyze_loss_cycle(cy_i=8)\n",
    "\n",
    "\"\"\"\n",
    "The peaks seem to narrow after cycle 4 independent of if the peak is loss at 4 or 5 or remainder\n",
    "Even when I fit the peaks they get darker so it isn't just a focus effect\n",
    "If it was a focus effect then they should be getting narrower after cy 4 but staying the same brightness (check in simulation)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare all peaks that dropped after cycle 4, cycle 5, and remainders\n",
    "\n",
    "\n",
    "# Compare various stats about these two groups.\n",
    "# Cy 0 brightness? Nope?\n",
    "debug(dropped_after_cy_4.sum())\n",
    "debug(remainders.sum())\n",
    "with z(_cols=3):\n",
    "    cy = 0\n",
    "    # Brightness at cy? Somewhat\n",
    "    with z(_merge=True, f_title=f\"Brightness at cy {cy}\", _legend=True, _bins=np.linspace(0, 18_000, 25), _density=True):\n",
    "        z.hist(sig[samp_iz][dropped_after_cy_4, cy], _label=\"Edmaned\", color=\"lightgray\")\n",
    "        z.hist(sig[samp_iz][remainders, cy], _label=\"Remainders\", _step=True, line_width=2)\n",
    "\n",
    "    # SNR at cy? Somewhat\n",
    "    with z(_merge=True, f_title=f\"SNR at cy {cy}\", _legend=True, _bins=np.linspace(0, 100, 25), _density=True):\n",
    "        z.hist(snr[samp_iz][dropped_after_cy_4, cy], _label=\"Edmaned\", color=\"lightgray\")\n",
    "        z.hist(snr[samp_iz][remainders, cy], _label=\"Remainders\", _step=True, line_width=2)\n",
    "\n",
    "    # Dist from center? Nope\n",
    "    with z(_merge=True, f_title=f\"Radius\", _legend=True, _density=True):\n",
    "        centered_locs = locs - [512, 512]\n",
    "        radius = np.sqrt(np.sum(centered_locs**2, axis=1))\n",
    "        z.hist(radius[samp_iz][dropped_after_cy_4], _label=\"Edmaned\", color=\"lightgray\")\n",
    "        z.hist(radius[samp_iz][remainders], _label=\"Remainders\", _step=True, line_width=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter eigen sum of PSF vs radiomwtey\n",
    "\n",
    "# psfs = run.sigproc_v2.psfs()\n",
    "# n_fields, n_channels, n_cycles, divs_h, divs_w, dim_h, dim_w = psfs.shape \n",
    "# divs = divs_h\n",
    "# assert divs == divs_w\n",
    "\n",
    "# ratios = np.zeros_like(psfs[:, :, :, :, :, 0, 0])\n",
    "\n",
    "# for fl, ch, cy in run.sigproc_v2.fl_ch_cy_iter():\n",
    "#     for y, x, in itertools.product(range(divs), range(divs)):\n",
    "#         psf = psfs[fl, ch, cy, y, x]\n",
    "#         ratios[fl, ch, cy, y, x] = imops.distribution_aspect_ratio(psf)\n",
    "# names = [\"field_i\", \"channel_i\", \"cycle_i\", \"reg_y\", \"reg_x\"]\n",
    "# index = pd.MultiIndex.from_product([range(s) for s in ratios.shape], names=names)\n",
    "# ratio_df = pd.DataFrame(dict(ratio=ratios.flatten()), index=index).reset_index()\n",
    "\n",
    "# bg = np.array(run.sigproc_v2.calib[\"regional_bg_mean.instrument_channel[0]\"])\n",
    "# names = [\"reg_y\", \"reg_x\"]\n",
    "# index = pd.MultiIndex.from_product([range(s) for s in bg.shape], names=names)\n",
    "# bg_df = pd.DataFrame(dict(bg=bg.flatten()), index=index).reset_index()\n",
    "\n",
    "# df = run.sigproc_v2.radmats__peaks()\n",
    "# df[\"reg_y\"] = np.floor(divs * df.aln_y / 1024).astype(int)\n",
    "# df[\"reg_x\"] = np.floor(divs * df.aln_x / 1024).astype(int)\n",
    "# df = df.set_index([\"field_i\", \"channel_i\", \"cycle_i\", \"reg_y\", \"reg_x\"]).join(\n",
    "#     ratio_df.set_index([\"field_i\", \"channel_i\", \"cycle_i\", \"reg_y\", \"reg_x\"])\n",
    "# ).reset_index()\n",
    "\n",
    "# df = df.set_index([\"reg_y\", \"reg_x\"]).join(\n",
    "#     bg_df.set_index([\"reg_y\", \"reg_x\"])\n",
    "# ).reset_index()\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# samps = data.arg_subsample(df.signal.values, 5000)\n",
    "# z.scat(x=df.signal[samps], y=df.ratio[samps], alpha=0.5, f_x_axis_label=\"signal\", f_y_axis_label=\"circularity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chcy_ims = run.ims_import.ims[0]\n",
    "# chcy_ims, locs, radmat, aln_offsets, aln_scores, chcy_regional_psfs = worker.sigproc_field(chcy_ims, run.sigproc_v2.params, run.sigproc_v2.calib())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# psfs = chcy_regional_psfs\n",
    "# n_fields = 1\n",
    "# n_channels, n_cycles, divs_h, divs_w, dim_h, dim_w = psfs.shape \n",
    "# #n_cycles = 8   # HACK\n",
    "\n",
    "# assert divs_h == divs_w\n",
    "# divs = divs_h\n",
    "# assert dim_h == dim_w\n",
    "# dim = dim_h\n",
    "# with z(_cols=n_cycles, _size=dim*divs*3, _notools=True, _noaxes=True, _cspan=np.percentile(psfs, (0, 100))):\n",
    "#     for ch, cy in itertools.product(range(n_channels), range(n_cycles)):\n",
    "#         comp = np.zeros((divs * dim, divs * dim))\n",
    "#         for y, x in itertools.product(range(divs), range(divs)):\n",
    "#             comp[y*dim:(y+1)*dim, x*dim:(x+1)*dim] = psfs[ch, cy, y, x]\n",
    "#         z.im(comp, f_title=f\"ch{ch} cy{cy}\")\n",
    "# np.all(psfs[0, 0, 0, 0] == psfs[0, 1, 0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# psf = psfs[0, 3, 0, 0]\n",
    "# z.im(psf)\n",
    "# imops.eigen_moments(psf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# psf = psfs[0, 5, 3, 3]\n",
    "# z.im(psf)\n",
    "# imops.eigen_moments(psf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with z(_cspan=np.percentile(chcy_ims, (0, 99)), _cols=2, _size=500):\n",
    "#     z.im(chcy_ims[0, 4])\n",
    "#     z.im(chcy_ims[0, 5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ch_i in range(run.ims_import.n_channels):\n",
    "    qdf = run.ims_import.qualities()\n",
    "    quality = qdf[qdf.channel_i == ch_i].sort_values([\"quality\"])\n",
    "    z.hist(quality.quality, _size_x=800, _size_y=150, f_title=f\"Quality distribution channel {ch_i}\")\n",
    "    \n",
    "    row_iz = utils.ispace(0, len(qdf), 3)\n",
    "    ims = np.array([\n",
    "        run.ims_import.ims[row.field_i, row.channel_i, row.cycle_i]    \n",
    "        for row in qdf.iloc[row_iz].itertuples()\n",
    "    ])\n",
    "    \n",
    "    with z(_cols=3, _cspan=np.percentile(ims, (30, 99))):\n",
    "        names = (\"worst\", \"median\", \"best\")\n",
    "        for im, name in zip(ims, names):\n",
    "            z.im(im, f_title=f\"Channel: {ch_i} {name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regional Illumination Balance and Channel Equalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "field_i = 0\n",
    "cycle_i = 0 \n",
    "\n",
    "ims = []\n",
    "for channel_i, channel_weight in zip(range(run.sigproc_v2.n_channels), run.sigproc_v2.channel_weights):\n",
    "    im = run.ims_import.ims[field_i, channel_i, cycle_i]\n",
    "    regional_balance = np.array(run.sigproc_v2.params.calibration[\"regional_illumination_balance.instrument_channel[0]\"])\n",
    "    balance_im = imops.interp(regional_balance, im.shape[-2:])\n",
    "    ims += [np.stack((im, im * balance_im * channel_weight))]\n",
    "ims = np.array(ims)\n",
    "cspan = np.percentile(ims, (30, 99))\n",
    "\n",
    "for channel_i in range(run.sigproc_v2.n_channels):\n",
    "    before_im = ims[channel_i, 0]\n",
    "    after_im = ims[channel_i, 1]\n",
    "    with z(_cols=2, _size=500, _cspan=cspan):\n",
    "        z.im(before_im, f_title=f\"Before balance (field {field_i}, channel_i {channel_i}, cycle {cycle_i})\")\n",
    "        z.im(after_im, f_title=\"After balance & equalization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=2)\n",
    "regional_balance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "field_df = run.sigproc_v2.fields().copy()\n",
    "field_df[\"align\"] = np.sqrt(field_df.aln_x**2 + field_df.aln_y**2)\n",
    "alignment = field_df.groupby(\"field_i\").align.max().values\n",
    "z.cols(alignment, f_x_axis_label=\"field_i\", f_y_axis_label=\"n_pixels\", f_title=\"Max. alignment dist.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ims = run.ims_import.ims[4, 0, :]\n",
    "with z(_cols=3, _cspan=np.percentile(ims, (20, 99))):\n",
    "    for cy in range(8):\n",
    "        z.im(ims[cy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ims = run.sigproc_v2.aln_ims[4, 0, :]\n",
    "with z(_cols=2, _cspan=np.nanpercentile(ims, (20, 99.9)), _size=700):\n",
    "    z.im(ims[4])\n",
    "    z.im(ims[5])\n",
    "\n",
    "    \n",
    "# Circle in the signed image all the spots that should have had zero change\n",
    "# Those that are sitl present.\n",
    "    \n",
    "z.im_signed(  0.001 * (ims[5] - ims[4]), _size=700 )\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_snr = np.nan_to_num(run.sigproc_v2.snr(flat_chcy=True))\n",
    "# all_sig = np.nan_to_num(run.sigproc_v2.signal_radmat(flat_chcy=True))\n",
    "# rows_with_high_snr = np.any(all_snr > 40.0, axis=1)\n",
    "\n",
    "# with z(\n",
    "#     f_x_axis_label=\"SNR\",\n",
    "#     _size_x=800,\n",
    "#     _size_y=200,\n",
    "#     _bins=np.linspace(0, 90, 300),\n",
    "# ):\n",
    "#     good_snr = all_snr.flatten()\n",
    "#     z.hist(\n",
    "#         good_snr[good_snr > 1.0],\n",
    "#         f_title=f\"SNR distribution of all rows (excl. darks)\",\n",
    "#     )\n",
    "\n",
    "#     good_snr = all_snr[~rows_with_high_snr].flatten()\n",
    "#     z.hist(\n",
    "#         good_snr[good_snr > 1.0],\n",
    "#         f_title=f\"SNR distribution of rows with no elements > 40 (excl. darks)\",\n",
    "#     )\n",
    "\n",
    "#     good_snr = all_snr[rows_with_high_snr].flatten()\n",
    "#     z.hist(\n",
    "#         good_snr[good_snr > 1.0],\n",
    "#         f_title=f\"SNR distribution of rows with any element SNR > 40 (excl. darks)\",\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "field_i = 4\n",
    "cycle_i = 0\n",
    "\n",
    "im = run.sigproc_v2.aln_ims[field_i, channel_i, cycle_i]\n",
    "sig = run.sigproc_v2.signal_radmat_for_field(field_i)[:, channel_i, cycle_i]\n",
    "noi = run.sigproc_v2.noise_radmat_for_field(field_i)[:, channel_i, cycle_i]\n",
    "snr = run.sigproc_v2.snr_for_field(field_i)[:, channel_i, cycle_i]\n",
    "locs = run.sigproc_v2.locs_for_field(field_i)\n",
    "\n",
    "keep_locs = snr > 20.0\n",
    "\n",
    "circle_im = worker.circle_locs(im, locs[keep_locs], inner_radius=3, outer_radius=4, fill_mode=\"index\")\n",
    "\n",
    "with z(_merge=True, _full=True):\n",
    "    z.im(im, _cper=(0, 100))\n",
    "\n",
    "    snr_im = snr[keep_locs][circle_im.astype(int)]\n",
    "    alpha_im = np.where(circle_im.astype(int) == 0, 0, 1)\n",
    "    z.im_blend(snr_im, alpha_im, _palette=\"inferno\", _nan=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PSF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_psfs(psfs):\n",
    "    n_fields, n_channels, n_cycles, divs_h, divs_w, dim_h, dim_w = psfs.shape \n",
    "    assert divs_h == divs_w\n",
    "    divs = divs_h\n",
    "    assert dim_h == dim_w\n",
    "    dim = dim_h\n",
    "    with z(_cols=n_cycles, _size=dim*divs*3, _notools=True, _noaxes=True, _cspan=np.percentile(psfs, (0, 100))):\n",
    "        for fl, ch, cy in itertools.product(range(n_fields), range(n_channels), range(n_cycles)):\n",
    "            comp = np.zeros((divs * dim, divs * dim))\n",
    "            for y, x in itertools.product(range(divs), range(divs)):\n",
    "                comp[y*dim:(y+1)*dim, x*dim:(x+1)*dim] = psfs[fl, ch, cy, y, x]\n",
    "            z.im(comp, f_title=f\"fl{fl} ch{ch} cy{cy}\")\n",
    "\n",
    "plot_psfs(run.sigproc_v2.psfs())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remainders vs Edmaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mea = 9\n",
    "noise = 0.002\n",
    "true_params = (1.0, 1.0, 1.0, 4, 4, 0.0, mea)\n",
    "orig_im = imops.gauss2_rho_form(*true_params)\n",
    "nois_im = orig_im + noise * np.random.randn(*orig_im.shape)\n",
    "fit_params, fit_variance = imops.fit_gauss2(nois_im)\n",
    "fit_im = imops.gauss2_rho_form(*fit_params)\n",
    "\n",
    "debug(np.sqrt(fit_variance / np.array(fit_params)[0:6]))\n",
    "\n",
    "with z(_cols=3, _size=200, _cspan=(0, 0.1)):\n",
    "    z.im(orig_im, f_title=\"original\")\n",
    "    z.im(nois_im, f_title=\"with noise\")\n",
    "    z.im(fit_im, f_title=\"from fit\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def im_with_circle(im, x, y):\n",
    "    circle_im = worker.circle_locs(im, [(0, 0), XY(x, y)], inner_radius=5, outer_radius=10, fill_mode=\"index\")\n",
    "    clr_im = np.full_like(im, 1)\n",
    "    with z(_merge=True, _full=True):\n",
    "        z.im(im, _cper=(10, 99))\n",
    "        alpha_im = np.where(circle_im.astype(int) == 0, 0, 1)\n",
    "        z.im_blend(clr_im, alpha_im, _palette=\"inferno\", _nan=0)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = run.sigproc_v2.peaks().sample(100)\n",
    "fit_params_cy4, fit_variances_cy4, sigs_cy4, nois_cy4 = fit_gaussian_peaks(run, df, 4)\n",
    "good_fits_cy4 = np.nan_to_num(fit_variances_cy4[:, 0], nan=1e6) < 300\n",
    "z.hist(fit_params_cy4[good_fits_cy4, 1], _bins=np.linspace(1, 4, 50))\n",
    "\n",
    "fit_params_cy5, fit_variances_cy5, sigs_cy5, nois_cy5 = fit_gaussian_peaks(run, df, 5)\n",
    "good_fits_cy5 = np.nan_to_num(fit_variances_cy5[:, 0], nan=1e6) < 300\n",
    "z.hist(fit_params_cy5[good_fits_cy5, 1], _bins=np.linspace(1, 4, 50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with z(_merge=True, f_x_axis_label=\"cy4 peak width\", f_y_axis_label=\"cy5 peak width\"):\n",
    "    z.scat(\n",
    "        x=fit_params_cy4[good_fits_cy4, 1],\n",
    "        y=fit_params_cy5[good_fits_cy4, 1],\n",
    "        _range=(0, 4, 0, 4)\n",
    "    )\n",
    "    z.line(x=[0, 4], y=[0, 4])\n",
    "    \n",
    "# Yes, the cycle 5 peaks are changing shape.\n",
    "# One possibility is that are narrower because the focus change\n",
    "# But, does the area under the curve change?\n",
    "z.im(gauss2_rho_form(*fit_params_cy4[0, :]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Radiometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histograms of derivatives\n",
    "channel_i = 0\n",
    "snr_thresh = 50.0\n",
    "\n",
    "sig = run.sigproc_v2.signal_radmat()[:, channel_i]\n",
    "snr = run.sigproc_v2.snr()[:, channel_i]\n",
    "snr = np.max(snr, axis=1)\n",
    "sig = sig[snr > snr_thresh]\n",
    "deriv = np.diff(sig, axis=1, prepend=0)\n",
    "span = np.max(np.abs(np.percentile(deriv, (1, 99))))\n",
    "\n",
    "with z(_bins=np.linspace(-span, span, 100), _cols=4, _size=250, _range=(-span, span, 0, 20_000)):\n",
    "    n_cycles = deriv.shape[1]\n",
    "    for cy_i in range(1, n_cycles):\n",
    "        z.hist(deriv[:, cy_i], f_title=f\"Cycle {cy_i-1} to cycle {cy_i}\", f_x_axis_label=\"Intensity change\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter of cycle to cycle values\n",
    "channel_i = 0\n",
    "snr_thresh = 5.0\n",
    "n_samples = 1000\n",
    "\n",
    "sig = run.sigproc_v2.signal_radmat()[:, channel_i]\n",
    "snr = run.sigproc_v2.snr()[:, channel_i]\n",
    "samp_iz = data.arg_subsample(sig, n_samples)\n",
    "sig = sig[samp_iz]\n",
    "snr = snr[samp_iz]\n",
    "\n",
    "snr = np.max(snr, axis=1)\n",
    "sig = sig[snr > snr_thresh]\n",
    "\n",
    "stacks = []\n",
    "n_cycles = deriv.shape[1]\n",
    "with z(_cols=4, _size=250, _range=(0, 60_000, 0, 60_000)):\n",
    "    for cy_i in range(0, n_cycles-1):\n",
    "        deltas = sig[:, cy_i:cy_i+2]\n",
    "        with z(\n",
    "            _merge=True,\n",
    "            f_x_axis_label=\"int. last cycle\",\n",
    "            f_y_axis_label=\"int. this cycle\",\n",
    "            f_title=f\"Correlation, cycle {cy_i} to {cy_i+1}\",\n",
    "        ):\n",
    "            z.scat(\n",
    "                x=deltas[:,0], y=deltas[:, 1], alpha=0.1,\n",
    "            )\n",
    "            z.line(x=[0, 60_000], y=[0, 60_000])\n",
    "        stacks += [deltas]\n",
    "\n",
    "all_deltas = np.vstack(stacks)\n",
    "z.scat(\n",
    "    x=all_deltas[:,0], y=all_deltas[:, 1], alpha=0.1,\n",
    "    f_x_axis_label=\"int. cycle n\", f_y_axis_label=\"int. cycle n+1\", f_title=f\"Correlation, all cycles\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histograms by cycle\n",
    "channel_i = 0\n",
    "\n",
    "\n",
    "center = np.median(run.sigproc_v2.signal_radmat()[:, channel_i, 0])  #5_000  # This is a reference line, move it around as you want\n",
    "\n",
    "with z(_cols=3, _size=250, _bins=np.linspace(0, 20000, 100), _range=(0, 20000, 0, 2000)):\n",
    "    for cy in range(n_cycles):\n",
    "        snr = run.sigproc_v2.snr()[:, channel_i, cy].flatten()\n",
    "        sig = run.sigproc_v2.signal_radmat()[:, channel_i, cy].flatten()\n",
    "        snr_mask = snr > 0\n",
    "        sig = sig[snr_mask]\n",
    "\n",
    "        with z(_merge=True):\n",
    "            z.hist(sig)#[sig > 2.])\n",
    "            z.line(x=[center, center], y=[0, 2000], color=\"red\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histograms by region\n",
    "channel_i = 0\n",
    "\n",
    "_n_cycles = 9\n",
    "snr = run.sigproc_v2.snr()[:, channel_i, :].flatten()\n",
    "sig = run.sigproc_v2.signal_radmat()[:, channel_i, :].flatten()\n",
    "locs = np.tile(run.sigproc_v2.locs(), (1, _n_cycles)).reshape((-1, 2))\n",
    "snr_mask = snr > 20\n",
    "sig = sig[snr_mask]\n",
    "locs = locs[snr_mask]\n",
    "\n",
    "top = np.max((locs[:, 0], locs[:, 1]))\n",
    "divs = 5\n",
    "y = utils.ispace(0, top, divs+1)\n",
    "x = utils.ispace(0, top, divs+1)\n",
    "\n",
    "center = np.median(sig[sig > 2.])\n",
    "\n",
    "means = np.zeros((divs, divs))\n",
    "with z(_cols=divs, _size=200, _bins=np.linspace(0, 30000, 100), _range=(0, 30000, 0, 1000)):\n",
    "    for yi in range(len(y)-2, -1, -1):  # Reverse because imags are first quadrant but plot grids are inverted\n",
    "        for xi in range(0, len(x)-1):\n",
    "            mask = (y[yi] <= locs[:, 0]) & (locs[:, 0] < y[yi+1])\n",
    "            mask &= (x[xi] <= locs[:, 1]) & (locs[:, 1] < x[xi+1])\n",
    "            _sig = sig[mask]\n",
    "            means[yi][xi] = np.mean(_sig[_sig > 2.])\n",
    "            with z(_merge=True):\n",
    "                z.hist(_sig[_sig > 2.])\n",
    "                z.line(x=[center, center], y=[0, 1000], color=\"red\")\n",
    "\n",
    "#     max_mean = np.max(means)\n",
    "#     for yi in range(len(y)-2, -1, -1):  # Reverse because imags are first quadrant but plot grids are inverted\n",
    "#         for xi in range(0, len(x)-1):\n",
    "#             mask = (y[yi] <= locs[:, 0]) & (locs[:, 0] < y[yi+1])\n",
    "#             mask &= (x[xi] <= locs[:, 1]) & (locs[:, 1] < x[xi+1])\n",
    "#             _sig = sig[mask]\n",
    "#             mean = np.mean(_sig[_sig > 2.])\n",
    "#             _sig *= max_mean / mean\n",
    "#             with z(_merge=True):\n",
    "#                 z.hist(_sig[_sig > 2.])\n",
    "#                 z.line(x=[center, center], y=[0, 1000], color=\"red\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Signal Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.sigproc_v2.radmats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plots.wizard_scat_df(run, result_block=\"sigproc_v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plots.wizard_xy_df(run, result_block=\"sigproc_v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plots.wizard_raw_images(run, show_circles=False, peak_i_square=True, square_radius=7, result_block=\"sigproc_v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
