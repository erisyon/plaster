{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @REMOVE-FROM-TEMPLATE\n",
    "from plaster.tools.ipynb_helpers.displays import restart_kernel; restart_kernel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# @IMPORT-MERGE\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from munch import Munch\n",
    "from plaster.tools.zplots import zplots\n",
    "from plaster.run.plots import plots\n",
    "from plaster.run.plots import plots_dev as pdev\n",
    "from plaster.run.plots import plots_dev_pro as ppro\n",
    "from plaster.run.plots import plots_dev_ptm as pptm\n",
    "from plaster.run.run import RunResult\n",
    "from plaster.run.job import JobResult, MultiJobResult\n",
    "from plaster.tools.ipynb_helpers.displays import hd\n",
    "from plaster.tools.log.log import error, debug, prof\n",
    "from plaster.tools.utils.utils import json_print, np_safe_divide, munch_abbreviation_string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @REMOVE-FROM-TEMPLATE\n",
    "z = zplots.setup()\n",
    "job = JobResult(\"/erisyon/internal/jobs_folder/bmf_2020_07_23_02_hemolysate_classify_v2\")\n",
    "\n",
    "# If you are running this report by dropping it into a job folder,\n",
    "# then comment the above and uncomment this line before running:\n",
    "# job = JobResult(\"./\")\n",
    "\n",
    "run = job.runs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optionally Edit your Proteins or PTMs of interest\n",
    "* These are typically specified when you create a plaster job\n",
    "* You needn't specify anything here unless you want to change this\n",
    "* Execute this cell to see the current setting.\n",
    "* This cell loads all PR data and may take some minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "which_classifier = \"nn_v2\"  # None to use best available, or e.g. 'rf' to request specific\n",
    "\n",
    "#\n",
    "# Add entries to this list to specify proteins of interest, and optionally locations\n",
    "# of interest on those proteins.  Note that if you don't set anything here, any\n",
    "# --protein_of_interest you specified via pgen will be used instead, and any PTM\n",
    "# locations given in a --protein_csv file will be used for that protein.\n",
    "#\n",
    "proteins_locations = [\n",
    "# These are examples.  Add your own that are not commented out.\n",
    "#     ( 'P10636-8', '181;184;185;199;202;214;231;237;404' ),\n",
    "#     ( 'P02768'  , '25' ),\n",
    "#     ( 'Q13885'  , '' )\n",
    "]\n",
    "\n",
    "# You should not edit anything below this point unless you're adventurous.  :)\n",
    "#\n",
    "# TODO: much/all of this code should get moved into a python file that is called from here.\n",
    "#===========================================================================================\n",
    "\n",
    "if len(proteins_locations) > 0:    \n",
    "    job.set_pros_of_interest(protein_ids=[tup[0] for tup in proteins_locations])\n",
    "    for poi, ptms in proteins_locations:\n",
    "        job.set_pro_ptm_locs(protein_id=poi, ptms=ptms)\n",
    "\n",
    "# If there are proteins of interest, reporting will be focused on those.\n",
    "# If those have PTM locations of interest, reporting will further focused on those.\n",
    "# The flags include_xxx_only determine which proteins/peptides are pulled into\n",
    "# the reporting -- you can override those if you want.\n",
    "columns = [\"pro_id\", \"pro_ptm_locs\"]\n",
    "if \"abundance\" in job.runs[0].prep.pros().columns:\n",
    "    columns += [\"abundance\"]\n",
    "proteins_of_interest = job.get_pros_of_interest().drop_duplicates(\"pro_id\")[columns]\n",
    "ptms_for_proteins = [job.get_pro_ptm_locs(poi) for poi in proteins_of_interest[\"pro_id\"].unique()]\n",
    "\n",
    "include_poi_only = len(proteins_of_interest) > 0  # poi only if there are some specified\n",
    "include_ptm_only = include_poi_only and all(ptms_for_proteins)\n",
    "\n",
    "# This section tells you what the reporting will be based on, and\n",
    "# loads precision/recall/scoring information for that domain.\n",
    "if not proteins_of_interest.empty:\n",
    "    print(\"Proteins of interest:\")\n",
    "    display(proteins_of_interest)\n",
    "    print()\n",
    "\n",
    "# Choose a classifier based on availability and user request at top of cell.\n",
    "available_classifiers = job.runs[0].get_available_classifiers()\n",
    "chosen_classifier = which_classifier if which_classifier in available_classifiers else available_classifiers[0]\n",
    "print(f\"Available classifiers : {available_classifiers}\")\n",
    "\n",
    "prs_args = Munch(\n",
    "    include_poi_only=include_poi_only,\n",
    "    include_ptm_only=include_ptm_only,\n",
    "    force_compute_prs=False,\n",
    "    classifier=chosen_classifier,\n",
    ")\n",
    "\n",
    "print(\"Loading PR information for peptides based on this:\")\n",
    "json_print(prs_args)\n",
    "print(\"\\nTakes a minute...\")\n",
    "\n",
    "all_runs_pr = job.peps_prs_report_df(**prs_args)\n",
    "all_runs_pr_abund = job.peps_prs_report_df(**prs_args, pr_with_abundance=True)\n",
    "print(\"done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Edit your filters and find best runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_runs_for_proteins(filters):\n",
    "    pr_df = all_runs_pr\n",
    "    abund_title = \"(equal abundance)\"\n",
    "    if filters.pr_with_abundance:\n",
    "        if all_runs_pr_abund is None:\n",
    "            abund_title = \"(no abundance information available)\"\n",
    "            filters.pr_with_abundance=False\n",
    "        else:\n",
    "            abund_title = \"(with abundance)\" \n",
    "            pr_df = all_runs_pr_abund\n",
    "            \n",
    "    hd(\"h1\", f\"Best runs per protein {abund_title}\")\n",
    "    #hd(\"h3\", \"Filters\")\n",
    "    #json_print(filters)\n",
    "    best_pr = job.get_best_precision_runs_for_pros(pr_df, filters)\n",
    "    run_info = pdev._run_iz_count_pep_iz(best_pr)\n",
    "    ppro.plot_best_runs_pr(best_pr, pr_df, run_info, filters, _size=640)\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    display(best_pr)\n",
    "    return best_pr\n",
    "\n",
    "def pr_for_a_protein(filters,pro=None):\n",
    "    #pr_df = all_runs_pr         \n",
    "    hd(\"h1\", f\"Best run per protein {pro}\")\n",
    "    best_pr = job.get_best_precision_runs_for_pros(all_runs_pr, filters)\n",
    "    run_info = pdev._run_iz_count_pep_iz(best_pr)\n",
    "    ppro.plot_best_runs_pr(best_pr, all_runs_pr, run_info, filters, _size=640)\n",
    "    display(best_pr[['run_name','pep_i','pep_start','pep_stop','prec','recall','run_i']])\n",
    "    return best_pr\n",
    "\n",
    "# Edit the filters here, then run this cell\n",
    "filters = Munch(\n",
    "    allow_proline_at_2=False,      # True or False\n",
    "    classifier=chosen_classifier,  # edit which_classifier in cell above to change this.\n",
    "    exclude_runs=[],               # [] or List of runs to exclude, e.g. ['gluc_ph4_c_k_de_y_9880']   \n",
    "    include_runs=[],               # [] or List of runs to consider, e.g. ['gluc_ph4_c_k_de_y_9880']\n",
    "    max_dyes_per_ch=4,             # None, or some integer\n",
    "    max_pep_len=50,                # None, or some integer\n",
    "    min_recall=0.1,                # floating point number between 0 and 1\n",
    "    n_best_runs=1,                 # integer >= 1\n",
    "    pr_with_abundance=True,        # adjust PR for available protein abundance information\n",
    "    pro_subset=[],                 # [] or subset of proteins to consider, e.g. ['Q8WXI7','P21217']\n",
    "                                   # Note the proteins_of_interest is already respected with []\n",
    "                                   # pro_subset is used to specify a further subset of these.\n",
    ")\n",
    "\n",
    "best_pr = best_runs_for_proteins(filters)\n",
    "if False: #set to True if you want PR curves for each POI individually\n",
    "    for index,row in proteins_of_interest.iterrows():\n",
    "        pro = row['pro_id']\n",
    "        filters['pro_subset'] = [pro]\n",
    "        best_pr = pr_for_a_protein(filters,pro)\n",
    "# The following line saves your best_pr dataframe to a CSV named for the filter settings.\n",
    "# user =  ''\n",
    "# best_pr.to_csv(f'./report_best_pr__{user}__{munch_abbreviation_string(filters)}.csv',index=False,float_format=\"%g\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Runs that produced at least one best-precision-at-recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change this to vary how many best precisions at min recall to show\n",
    "nbr_best_to_show = 15\n",
    "\n",
    "# Execute this cell to get a standard report on each run that produced at least one\n",
    "# best precision-recall for a peptide.\n",
    "#\n",
    "# Or call run_report with your run_i of interest.\n",
    "def run_report(run_i):\n",
    "    run = job.runs[run_i]\n",
    "    hd(\"h1\", \"_________________________________________________________________\")\n",
    "    plots.standard_run_report( run, classifier=filters.classifier )\n",
    "\n",
    "    hd(\"h3\", f\"Top {nbr_best_to_show} best precisions at min_recall={filters.min_recall} {filters.classifier}\")\n",
    "    df = pdev.peps_prec_at_min_recall_df(all_runs_pr[all_runs_pr.run_i==run_i], min_recall=filters.min_recall)\n",
    "    df = df.sort_values(by=[\"prec\", \"recall\"], ascending=[False, False])\n",
    "    display(df.head(nbr_best_to_show)) \n",
    "    print()\n",
    "    \n",
    "    # Rendering of large confusion matricies are crashing the brower\n",
    "    # removed until we can figure out how to display better\n",
    "    #hd('h2', f\"Confusion Matrix, with & without score threshold (best precision pep_i)\")\n",
    "    #row = best_pr[best_pr.run_i==run_i].sort_values(by=['prec','recall'],ascending=[False,False]).iloc[0]\n",
    "    #pdev.plot_confusion_matrix_compare( job.runs[run_i],row.pep_i,row.score, classifier=filters.classifier )\n",
    "\n",
    "\n",
    "# Set to True to get a standard run report on each run that produced a \"best pr\"\n",
    "run_info = pdev._run_iz_count_pep_iz(best_pr)\n",
    "if False:\n",
    "    for run_i in run_info.run_iz:\n",
    "        run_report(run_i)\n",
    "\n",
    "\n",
    "# Or get a report on a specific run_i\n",
    "# run_info.run_iz is a list of run_i sorted by best->worst based on filter\n",
    "# best = produces most peptides with \"best pr\" of all runs\n",
    "if True:\n",
    "    run_i = run_info.run_iz[0]  # run_iz is sorted from best->worst\n",
    "    run_report(run_i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore fluorosequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# To explore details for a given fluorosequence:\n",
    "#\n",
    "# Edit the flu and run you want to explore & set to True\n",
    "\n",
    "if False:\n",
    "    flu = '1..21...01..... ;0,0,0'\n",
    "    run_i = run_info.run_iz[0]\n",
    "    peps_prs_df = all_runs_pr[(all_runs_pr.run_i==run_i)&(all_runs_pr.flustr==flu)]\n",
    "    pdev.plot_flu_info( job.runs[run_i], flu, peps_prs_df=peps_prs_df, min_recall=filters.min_recall, classifier=filters.classifier )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore imposters by peptide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you want to explore imposters, set this to true and\n",
    "# update the several parameters below for your peptide.\n",
    "show_imposters=False\n",
    "\n",
    "# the run you are interested in\n",
    "run_i = 1\n",
    "\n",
    "# the peptide you are interested in\n",
    "pep_i = 259 \n",
    "\n",
    "# Score Threshold:\n",
    "# Only classifier calls with score above score_threshold are considered.\n",
    "# Start with any number in [0,1] like 0.5, or look this up in a table above where\n",
    "# you saw your peptide along with a precision, recall, and score.  You should\n",
    "# get back the same precision and recall if you use the same score.\n",
    "#\n",
    "# If score_threshold is 0, no classifier calls will be dropped.\n",
    "# The higher the threshold is set, the more classifier calls will be dropped.\n",
    "# Exactly how many is shown as those assigned to pep_i==0 in the False Negatives list.\n",
    "#\n",
    "# As the score_threshold goes up, the precision will also go up, and \n",
    "# the recall will go down, as we drop classifier calls which were scored \n",
    "# below the threshold (and more likely to be wrong than those above).\n",
    "score_threshold = 0.42\n",
    "\n",
    "# Do we want abundance taken into account?\n",
    "with_abundance=True\n",
    "\n",
    "# How many top imposters of each class (False Positives, False Negatives) to show\n",
    "topN = 20\n",
    "\n",
    "\n",
    "#########################################################################################\n",
    "# Users shouldn't need to edit anything below here\n",
    "\n",
    "if show_imposters:\n",
    "    cb = job.runs[run_i].test_call_bag(classifier=filters.classifier)\n",
    "    cm = cb.conf_mat_at_score_threshold( score_threshold )\n",
    "\n",
    "    # scale confusion matrix by abundance if desired.\n",
    "    if with_abundance:\n",
    "        pep_abundance = cb._prep_result.peps_abundance()\n",
    "        if pep_abundance is None:\n",
    "            print( \"*** abundance requested but none available.\")\n",
    "            with_abundance=False\n",
    "        else:\n",
    "            cm = cm.scale_by_abundance(pep_abundance)\n",
    "            print( f\"abundance of pep {pep_i} is {pep_abundance[pep_i]}\")\n",
    "\n",
    "    hd('h3',f'run {run_i}, pep {pep_i}, score_threshold {score_threshold}, abundance: {with_abundance}')\n",
    "\n",
    "    print(\"confusion matrix shape\", cm.shape)\n",
    "\n",
    "    predictions = cm[pep_i,:]\n",
    "    print(\"precision\",cm.precision()[pep_i])\n",
    "\n",
    "    truths = cm[:,pep_i]\n",
    "    print(\"recall\",cm.recall()[pep_i])\n",
    "\n",
    "    print(f\"total pep{pep_i} present: {np.sum(truths)}\")\n",
    "    print(f\"total correct predictions to pep{pep_i}: {predictions[pep_i]}\")\n",
    "    print(f\"total wrong predictions to pep{pep_i}: {np.sum(predictions)-predictions[pep_i]}\")\n",
    "\n",
    "\n",
    "    hd('h3',f'Top{topN} predictions of any peptide to peptide {pep_i} (i.e. False Positives)')\n",
    "\n",
    "    top_row_peps = np.argsort(predictions)[-topN:][::-1]\n",
    "    top_row_peps_counts = predictions[top_row_peps]\n",
    "\n",
    "    top_row_df = pd.DataFrame( Munch(pep_i=top_row_peps,n_predictions=top_row_peps_counts))\n",
    "    display(top_row_df)\n",
    "\n",
    "    peps_flus_etc = cb.peps__pepstrs__flustrs__p2()\n",
    "\n",
    "    top_row_peps_info = peps_flus_etc[peps_flus_etc.pep_i.isin(top_row_df.pep_i)].copy().set_index('pep_i').join(top_row_df.set_index('pep_i')).sort_values('n_predictions',ascending=False).reset_index()\n",
    "    display(top_row_peps_info)\n",
    "\n",
    "\n",
    "    hd('h3',f'Top{topN} predictions of peptide {pep_i} to any peptide (i.e. False Negatives)')\n",
    "\n",
    "    top_col_peps = np.argsort(truths)[-topN:][::-1]\n",
    "    top_col_peps_counts = truths[top_col_peps]\n",
    "\n",
    "    top_col_df = pd.DataFrame( Munch(pep_i=top_col_peps,n_predictions=top_col_peps_counts))\n",
    "    display(top_col_df)\n",
    "\n",
    "    top_col_peps_info = peps_flus_etc[peps_flus_etc.pep_i.isin(top_col_df.pep_i)].copy().set_index('pep_i').join(top_col_df.set_index('pep_i')).sort_values('n_predictions',ascending=False).reset_index()\n",
    "    display(top_col_peps_info)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# runs_pr_falses.csv for selected runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @REMOVE-FROM-TEMPLATE\n",
    "PGEN_report_precisions = (0.9,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#==========================================================================================\n",
    "# Edit your desired parameters here\n",
    "#==========================================================================================\n",
    "precisions = PGEN_report_precisions  # see above cell, or cell at top of notebook\n",
    "n_falses = 1\n",
    "protein_of_interest_only = False  \n",
    "\n",
    "# This controls the ordering of the columns in the csv\n",
    "cols = ['run_i', 'run_name', 'pro_i', 'pro_id', 'pep_i', 'pep_start', 'pep_stop', 'at_prec', 'recall_at_prec', 'score_at_prec', 'ptms', 'P2', 'seqstr', 'seqlen', 'flustr', 'flu_pros', 'false_i', 'false_type', 'false_pro_i', 'false_pep_i','false_flustr', 'false_weight']\n",
    "\n",
    "# This controls the default sorting\n",
    "sort = ['run_i','pro_i','pep_start', 'at_prec', 'recall_at_prec', 'pep_i', 'false_weight' ]\n",
    "ascend = [True,True,True,False,False,True,False]\n",
    "\n",
    "#==========================================================================================\n",
    "\n",
    "def pr_falses_for_best_runs(_run_info, prec, n_falses, protein_of_interest_only, classifier):\n",
    "    df_list = []\n",
    "    for run_i in _run_info.run_iz:\n",
    "        run = job.runs[run_i]\n",
    "        bag = run.test_call_bag( classifier=classifier )\n",
    "        df = bag.false_rates_all_peps__ptm_info(prec, n_falses, protein_of_interest_only)\n",
    "        df[\"run_i\"] = run_i\n",
    "        df[\"run_name\"] = run.manifest.run_name\n",
    "        df_list += [df]\n",
    "    return pd.concat(df_list).reset_index(drop=True)\n",
    "\n",
    "pep_false_df = pd.concat([\n",
    "    pr_falses_for_best_runs(run_info, prec, n_falses, protein_of_interest_only=protein_of_interest_only, classifier=filters.classifier)\n",
    "    for prec in precisions\n",
    "]).sort_values(by=sort,ascending=ascend).reset_index()[cols]\n",
    "\n",
    "if False:\n",
    "    hd('h3','peptides with non-zero recall at precision thresholds (avail as pep_false_df)')\n",
    "    \n",
    "    filename = f\"./runs_pr_falses__{'_'.join(map(str,precisions))}__{munch_abbreviation_string(filters)}.csv\"\n",
    "    pep_false_df.to_csv(filename,index=False,float_format=\"%g\")\n",
    "    print( f\"Wrote full pep_false_df to: {filename}\")\n",
    "    \n",
    "    display(pep_false_df[pep_false_df.recall_at_prec>0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
